{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259cb97f-caac-40a8-afcd-2472003fcbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline # Useful for combining vectorizer and model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib # To save the trained model\n",
    "\n",
    "print(\"Modeling libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c9ac9-829b-4c91-b566-0cbccd793487",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 1 - Load Cleaned and Enriched Data \n",
    "\n",
    "Before we can build any machine learning models, we need to load the dataset that we have cleaned and prepared during the Exploratory Data Analysis (EDA) phase. This dataset should contain the essential information we need for modeling, including the text of the reviews and the target variable we want to predict. \n",
    "\n",
    "In this project, our goal for modeling is to predict the sentiment of a review. During EDA, we used the VADER sentiment analysis tool to calculate a sentiment score (VADER_Score) and classify each review into categories (VADER_Sentiment: Positive, Negative, Neutral). This VADER_Sentiment column will serve as our target variable (y) for the classification model. \n",
    "\n",
    "This cell performs the following actions: \n",
    "\n",
    "    Load Data: It attempts to read the CSV file (cleaned_reviews_data.csv) that should have been saved at the end of the 02_eda_insights.ipynb notebook.\n",
    "    Verify Data: It prints basic information about the loaded data (shape, first few rows, column info) to confirm it loaded correctly.\n",
    "    Check for Target Variable: Crucially, it checks whether the VADER_Sentiment column is present in the loaded data. This column is essential for training our sentiment classification model.\n",
    "    Provide Guidance: If the VADER_Sentiment column is missing, it provides helpful messages:\n",
    "        It confirms the column is missing.\n",
    "        It checks for the Rating column as a potential fallback to create a simple sentiment label.\n",
    "        It provides example code on how to create a Simple_Sentiment label from the Rating if needed.\n",
    "         \n",
    "    Handle Errors: It includes error handling to provide clear messages if the file is not found or if any other unexpected error occurs during loading.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc000c9e-ceb5-4c1a-8f4d-b61f443211e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'cleaned_reviews_data.csv'.\n",
      "DataFrame shape: (1500, 19)\n",
      "\n",
      "--- First 5 Rows ---\n",
      "   ReviewID     AppName                     PlayStoreReviewID       UserName  \\\n",
      "0         1  AliExpress  2cf4e22e-e7e5-46df-acff-cd77eaf9de9d  Blaise Hytrek   \n",
      "1         2  AliExpress  da753698-5370-40b4-808b-eb0a3ce149a0   David Campos   \n",
      "2         3  AliExpress  b769d4ac-1b9b-4a3d-b399-04abc34aaeb0      Lee Davis   \n",
      "3         4  AliExpress  e849cdda-2ff9-4fac-b531-40b021d504ec      Jing Wang   \n",
      "4         5  AliExpress  d8989ff9-2a7e-406b-8dfd-faf8bd48c884   Kari Eilrich   \n",
      "\n",
      "                                        UserImageURL  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                          ReviewText  Rating  ThumbsUpCount  \\\n",
      "0  Good prices but awful shipping fees. Difficult...       2             24   \n",
      "1  Easy experience the last few years. Have done ...       5           1444   \n",
      "2  Alright. There's a LOT good deals, save for th...       5            161   \n",
      "3  extremely bad. when its affiliated store cance...       1            131   \n",
      "4  The first order of 3 items for .99Â¢ is real. H...       1            830   \n",
      "\n",
      "  AppVersion           ReviewDate ReplyContent RepliedAt  \\\n",
      "0    8.133.3  2025-07-18 03:22:39          NaN       NaN   \n",
      "1    8.129.3  2025-05-26 11:23:12          NaN       NaN   \n",
      "2    8.131.2  2025-07-04 21:14:16          NaN       NaN   \n",
      "3    8.131.2  2025-06-29 09:30:11          NaN       NaN   \n",
      "4    8.122.3  2025-03-08 03:32:58          NaN       NaN   \n",
      "\n",
      "                    ScrapedAt  \\\n",
      "0  2025-07-25 22:36:06.313333   \n",
      "1  2025-07-25 22:36:06.323333   \n",
      "2  2025-07-25 22:36:06.330000   \n",
      "3  2025-07-25 22:36:06.336666   \n",
      "4  2025-07-25 22:36:06.343333   \n",
      "\n",
      "                                   CleanedReviewText  ReviewWordCount  \\\n",
      "0  good price awful shipping fee difficult track ...               35   \n",
      "1  easy experience last year done shopping tech p...               34   \n",
      "2  alright lot good deal save shipping fault alie...               36   \n",
      "3  extremely bad affiliated store cancel one orde...               45   \n",
      "4  first order item real however upgraded bit get...               44   \n",
      "\n",
      "  YearMonth  Year  VADER_Score VADER_Sentiment  \n",
      "0   2025-07  2025      -0.7783        Negative  \n",
      "1   2025-05  2025       0.2960        Positive  \n",
      "2   2025-07  2025       0.9601        Positive  \n",
      "3   2025-06  2025      -0.7496        Negative  \n",
      "4   2025-03  2025       0.6908        Positive  \n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ReviewID           1500 non-null   int64  \n",
      " 1   AppName            1500 non-null   object \n",
      " 2   PlayStoreReviewID  1500 non-null   object \n",
      " 3   UserName           1500 non-null   object \n",
      " 4   UserImageURL       1500 non-null   object \n",
      " 5   ReviewText         1500 non-null   object \n",
      " 6   Rating             1500 non-null   int64  \n",
      " 7   ThumbsUpCount      1500 non-null   int64  \n",
      " 8   AppVersion         1373 non-null   object \n",
      " 9   ReviewDate         1500 non-null   object \n",
      " 10  ReplyContent       672 non-null    object \n",
      " 11  RepliedAt          672 non-null    object \n",
      " 12  ScrapedAt          1500 non-null   object \n",
      " 13  CleanedReviewText  1500 non-null   object \n",
      " 14  ReviewWordCount    1500 non-null   int64  \n",
      " 15  YearMonth          1500 non-null   object \n",
      " 16  Year               1500 non-null   int64  \n",
      " 17  VADER_Score        1500 non-null   float64\n",
      " 18  VADER_Sentiment    1500 non-null   object \n",
      "dtypes: float64(1), int64(5), object(13)\n",
      "memory usage: 222.8+ KB\n",
      "None\n",
      "\n",
      "--- Checking for Sentiment Columns ---\n",
      "'VADER_Sentiment' column found.\n",
      "\n",
      "--- Sentiment Distribution (VADER) ---\n",
      "VADER_Sentiment\n",
      "Positive    1031\n",
      "Negative     421\n",
      "Neutral       48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Cleaned Data\n",
    "# Assuming you saved it as 'cleaned_reviews_data.csv' in the previous phase\n",
    "data_file = 'cleaned_reviews_data.csv' # <-- Make sure this filename is correct!\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(f\"Data loaded successfully from '{data_file}'.\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(\"\\n--- First 5 Rows ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    print(df.info())\n",
    "\n",
    "    # --- Check for VADER_Sentiment column ---\n",
    "    print(\"\\n--- Checking for Sentiment Columns ---\")\n",
    "    if 'VADER_Sentiment' in df.columns:\n",
    "        print(\"'VADER_Sentiment' column found.\")\n",
    "        print(\"\\n--- Sentiment Distribution (VADER) ---\")\n",
    "        print(df['VADER_Sentiment'].value_counts())\n",
    "    else:\n",
    "        print(\"Warning: 'VADER_Sentiment' column NOT found in the loaded data.\")\n",
    "        # Check if Rating column exists, as a potential fallback\n",
    "        if 'Rating' in df.columns:\n",
    "            print(\"'Rating' column found. You can derive a simple sentiment from it if needed.\")\n",
    "            print(\"Example distribution of Ratings:\")\n",
    "            print(df['Rating'].value_counts().sort_index())\n",
    "            print(\"\\nTo create a simple sentiment label, you can add a cell like this:\")\n",
    "            print(\"df['Simple_Sentiment'] = df['Rating'].apply(lambda r: 'Positive' if r >= 4 else ('Negative' if r <= 2 else 'Neutral'))\")\n",
    "            print(\"Then use 'Simple_Sentiment' as your target variable (y) in the modeling.\")\n",
    "        else:\n",
    "            print(\"Error: Neither 'VADER_Sentiment' nor 'Rating' column found. Cannot proceed with standard sentiment modeling.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{data_file}' not found. Please ensure the EDA phase saved the file correctly.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading the  {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc() # This will print the full error traceback for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f148c6-4a3d-4928-af36-2509758b3e4b",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 2 - Define Features (X) and Target (y) \n",
    "\n",
    "In machine learning, we build models to learn a relationship between input features (X) and a target variable (y). For our sentiment classification task, we need to define what these are: \n",
    "\n",
    "    Features (X): These are the input data the model will use to make its predictions. In text classification, the most important feature is usually the text itself. Here, we will use the CleanedReviewText column. This column contains the pre-processed review text (lowercased, HTML removed, etc.) that we created during the Data Cleaning & Preprocessing phase. Each entry in X will be a single cleaned review string.\n",
    "    Target (y): This is the variable we want the model to predict. It's the \"correct answer\" we have in our dataset. For this task, the target is the sentiment category of each review. We will use the VADER_Sentiment column we created during EDA. Each entry in y will be a label like 'Positive', 'Negative', or 'Neutral'.\n",
    "     \n",
    "\n",
    "This cell performs the following actions: \n",
    "\n",
    "    Assign Features: It assigns the CleanedReviewText column from the DataFrame df to the variable X.\n",
    "    Assign Target: It assigns the VADER_Sentiment column from the DataFrame df to the variable y.\n",
    "    Print Information: It prints the shapes of X and y to confirm they have the expected number of entries (rows). For X, the shape should be (number_of_reviews,). For y, it should be (number_of_reviews,).\n",
    "    Check Class Distribution: It prints the value counts of y to see how many reviews belong to each sentiment category (Positive, Negative, Neutral). Understanding this distribution is important because it tells us if our dataset is balanced or imbalanced across classes.\n",
    "    Handle Missing Features: Although unlikely since you cleaned the data, it's good practice to check if there are any missing values (NaN) in our feature column CleanedReviewText. If any are found, it removes the corresponding rows from both X and y to ensure our features and targets stay aligned.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb69b32-a055-4de9-af5d-c234a12c029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) and Target (y) defined.\n",
      "X shape: (1500,)\n",
      "y shape: (1500,)\n",
      "\n",
      "--- Value counts of Target (y) ---\n",
      "VADER_Sentiment\n",
      "Positive    1031\n",
      "Negative     421\n",
      "Neutral       48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in CleanedReviewText: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Prepare Features and Target\n",
    "# Features (X): The cleaned text\n",
    "X = df['CleanedReviewText']\n",
    "\n",
    "# Target (y): The sentiment label we want to predict\n",
    "# Assuming 'VADER_Sentiment' exists from EDA\n",
    "y = df['VADER_Sentiment']\n",
    "\n",
    "print(\"Features (X) and Target (y) defined.\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"\\n--- Value counts of Target (y) ---\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check for any missing text data\n",
    "missing_text = X.isnull().sum()\n",
    "print(f\"\\nMissing values in CleanedReviewText: {missing_text}\")\n",
    "\n",
    "# Drop rows with missing text (if any)\n",
    "if missing_text > 0:\n",
    "    initial_shape = df.shape\n",
    "    df_clean = df.dropna(subset=['CleanedReviewText'])\n",
    "    X = df_clean['CleanedReviewText']\n",
    "    y = df_clean['VADER_Sentiment'] # Update y as well\n",
    "    print(f\"Dropped {initial_shape[0] - df_clean.shape[0]} rows due to missing CleanedReviewText.\")\n",
    "    print(f\"New X shape: {X.shape}, New y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966e49e-d750-407a-b2df-fc81272b72a5",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "    Positive: 1031 reviews\n",
    "    Negative: 421 reviews\n",
    "    Neutral: 48 reviews\n",
    "    Implication: Your dataset is imbalanced. The 'Positive' class significantly outnumbers the 'Negative' and especially the 'Neutral' classes. This is common in sentiment analysis (people often write more positive or negative reviews than neutral ones). Be aware of this for model evaluation; accuracy alone might be misleading (a model predicting 'Positive' all the time would be quite accurate). Metrics like Precision, Recall, and F1-score for each class, or a confusion matrix, will be more informative.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c00a1a-1d30-472c-913e-fa3b9842dfa3",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 3 - Split Data into Training and Testing Sets \n",
    "\n",
    "Before training any machine learning model, it's crucial to evaluate its performance on data it has never seen before. This prevents us from simply measuring how well the model memorizes the training data (which would lead to overfitting) and instead gives us an estimate of how well it will generalize to new, unseen reviews. \n",
    "\n",
    "To achieve this, we split our dataset into two distinct parts: \n",
    "\n",
    "    Training Set: This portion (typically 80%, as specified by test_size=0.2) is used to train the model. The model learns the relationship between the input text features (X_train) and the target sentiment labels (y_train).\n",
    "    Testing Set: This portion (the remaining 20%) is held back and not used during training. After the model is trained, we use this unseen data (X_test) to make predictions. We then compare these predictions (y_pred) against the known true labels (y_test) to calculate performance metrics.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7efa61ec-be53-4209-a3b4-aeee657e18f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets.\n",
      "Training set size: 1200\n",
      "Testing set size: 300\n",
      "\n",
      "--- Training Set Sentiment Distribution ---\n",
      "VADER_Sentiment\n",
      "Positive    825\n",
      "Negative    337\n",
      "Neutral      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Testing Set Sentiment Distribution ---\n",
      "VADER_Sentiment\n",
      "Positive    206\n",
      "Negative     84\n",
      "Neutral      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # stratify=y maintains class distribution\n",
    "\n",
    "print(\"Data split into training and testing sets.\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "print(\"\\n--- Training Set Sentiment Distribution ---\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\n--- Testing Set Sentiment Distribution ---\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0cf12-1b4a-40c6-a9a8-1b8d5fb59cea",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 4 - Define Machine Learning Models (Pipelines) \n",
    "\n",
    "Now that we have our data split into training and testing sets, we need to define the machine learning models we want to evaluate for the task of predicting sentiment from review text. Since our features are text (CleanedReviewText), we first need to convert them into numerical vectors that machine learning algorithms can process. This process is called vectorization or feature extraction. \n",
    "\n",
    "We will use Pipelines from Scikit-learn. A Pipeline is a powerful tool that chains together multiple processing steps (like vectorization and classification) into a single object. This ensures that the same sequence of transformations is applied consistently to both the training and testing data, preventing data leakage and simplifying the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15624024-b934-428e-9960-70b4178ef7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pipelines defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Models\n",
    "# Define the models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')), # Example parameters\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]),\n",
    "    \"Naive Bayes\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Model pipelines defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16a24-65a6-448e-b569-c17514a9917f",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 5 - Train and Evaluate Models \n",
    "\n",
    "With our data prepared and our model pipelines defined, we can now proceed to the core of the machine learning process: training the models and evaluating their performance. This step is crucial for determining which algorithm works best for our specific task of predicting sentiment from e-commerce app reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c899feb4-6095-43a4-a47c-1122af4253b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression ---\n",
      "Logistic Regression Accuracy: 0.7600\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Random Forest Accuracy: 0.7267\n",
      "\n",
      "--- Training Naive Bayes ---\n",
      "Naive Bayes Accuracy: 0.7033\n",
      "\n",
      "--- Best Model ---\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Train and Evaluate Models\n",
    "model_performance = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    # Fit the model (this includes fitting the TfidfVectorizer on X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    model_performance[name] = {\n",
    "        'model': model, # Store the trained pipeline\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "# Find the best model based on accuracy\n",
    "best_model_name = max(model_performance, key=lambda k: model_performance[k]['accuracy'])\n",
    "best_model = model_performance[best_model_name]['model']\n",
    "best_accuracy = model_performance[best_model_name]['accuracy']\n",
    "best_predictions = model_performance[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n--- Best Model ---\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
    "#print(f\"prediction: {best_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95473db4-5aba-4a9f-9a32-1c3627e12034",
   "metadata": {},
   "source": [
    "# Here's the interpretation of the output: \n",
    "\n",
    "    Model Training and Evaluation: \n",
    "        Logistic Regression: Trained and achieved an accuracy of 0.7600 (or 76.00%) on the test set.\n",
    "        Random Forest: Trained and achieved an accuracy of 0.7267 (or 72.67%) on the test set.\n",
    "        Naive Bayes: Trained and achieved an accuracy of 0.7033 (or 70.33%) on the test set.\n",
    "        (Note: The print statements within the loop confirmed each model trained and gave its respective accuracy.)\n",
    "         \n",
    "\n",
    "    Best Model Selection: \n",
    "        The code automatically compared the accuracies of the three models.\n",
    "        --- Best Model ---: This section confirms the results of the comparison.\n",
    "        Model: Logistic Regression: LogisticRegression achieved the highest accuracy (0.7600) among the three tested models and is therefore identified as the best model based on this metric.\n",
    "        Accuracy: 0.7600: This reiterates the accuracy score of the best model.\n",
    "        prediction: [...]: This line prints the array of predictions made by the best model (Logistic Regression) on the 300 test reviews. While it shows the predictions are a mix of 'Negative' and 'Positive' (and likely 'Neutral', though not visible in this truncated view), \n",
    "         \n",
    "     \n",
    "\n",
    "Conclusion: \n",
    "\n",
    "This step was successful. You have trained three different machine learning models for sentiment classification: \n",
    "\n",
    "    Logistic Regression (Best): 76.00% Accuracy\n",
    "    Random Forest: 72.67% Accuracy\n",
    "    Naive Bayes: 70.33% Accuracy\n",
    "     \n",
    "\n",
    "Based on test set accuracy, Logistic Regression performed the best. While 76% accuracy is a reasonable starting point, it's important to remember: \n",
    "\n",
    "    Accuracy Alone Can Be Misleading: Especially with your imbalanced dataset (Positive >> Negative >> Neutral), a model could achieve relatively high accuracy by simply predicting the majority class ('Positive') most of the time. The detailed evaluation in the next step will provide more insight.\n",
    "    It's a Baseline: This is the performance of these specific models (with the chosen parameters like max_features=5000, ngram_range=(1,2)) on this specific dataset split. There might be room for improvement through hyperparameter tuning or trying other algorithm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a007838-c033-47d2-964e-edfd2342582e",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 6 - Detailed Evaluation of the Best Model \n",
    "\n",
    "While overall accuracy gives us a quick snapshot of model performance, it doesn't tell the whole story, especially for imbalanced datasets like yours (where 'Positive' reviews significantly outnumber 'Negative' and 'Neutral'). To gain a deeper understanding of how well our best model (Logistic Regression, in this case) performs for each sentiment class, we need more detailed evaluation metrics. \n",
    "\n",
    "This cell performs the following actions: \n",
    "\n",
    "    Classification Report: \n",
    "        It generates a detailed classification report using sklearn.metrics.classification_report.\n",
    "        This report provides metrics for each class ('Negative', 'Neutral', 'Positive') individually, as well as macro and weighted averages:\n",
    "            Precision: Of all reviews predicted as a specific class (e.g., Positive), what percentage were actually that class? (True Positives / (True Positives + False Positives)). High precision means few false alarms for that class.\n",
    "            Recall (Sensitivity): Of all reviews that were actually a specific class (e.g., Positive), what percentage were correctly predicted as that class? (True Positives / (True Positives + False Negatives)). High recall means the model finds most instances of that class.\n",
    "            F1-Score: The harmonic mean of Precision and Recall. It provides a single score that balances both metrics, especially useful when Precision and Recall trade off against each other. An F1-score closer to 1.0 is better.\n",
    "            Support: The actual number of instances of each class in the test set (y_test).\n",
    "             \n",
    "        This report is crucial for understanding if the model struggles more with identifying 'Negative' reviews versus 'Positive' ones, or if 'Neutral' reviews are particularly challenging.\n",
    "         \n",
    "\n",
    "    Confusion Matrix Visualization: \n",
    "        It calculates the confusion matrix using sklearn.metrics.confusion_matrix. This matrix shows the counts of correct and incorrect predictions for each class pair.\n",
    "        It then visualizes this matrix using a heatmap (seaborn.heatmap).\n",
    "        The Y-axis represents the True Labels.\n",
    "        The X-axis represents the Predicted Labels.\n",
    "        Each cell [i, j] in the heatmap shows how many instances of the true class i were predicted as class j.\n",
    "        The diagonal elements represent correct predictions.\n",
    "        Off-diagonal elements represent misclassifications. For example, the cell at (True='Negative', Predicted='Positive') shows how many Negative reviews were incorrectly classified as Positive.\n",
    "        This visualization makes it easy to spot patterns in the model's errors (e.g., Does it confuse 'Neutral' with 'Positive' a lot?).\n",
    "         \n",
    "\n",
    "    Feature Importance Analysis (for Logistic Regression): \n",
    "        Since the best model is Logistic Regression (a linear model), we can inspect the coefficients assigned to features (words/bigrams) to understand what the model considers important for predicting each sentiment.\n",
    "        The code accesses the trained TfidfVectorizer and LogisticRegression classifier from within the best_model pipeline using best_model.named_steps['step_name'].\n",
    "        It retrieves the names of the features (words/bigrams) generated by the vectorizer.\n",
    "        It accesses the coefficients (coef_) of the Logistic Regression model. These coefficients indicate the weight or importance of each feature for predicting each class.\n",
    "        It identifies the features with the highest positive coefficients for the 'Positive' class. These are the words/phrases the model strongly associates with positive sentiment.\n",
    "        It identifies the features with the highest positive coefficients for the 'Negative' class. These are the words/phrases the model strongly associates with negative sentiment.\n",
    "        It prints the Top 20 features for both 'Positive' and 'Negative' sentiment, showing the feature name and its coefficient value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb677c42-0058-495e-9040-bea3df9ba258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detailed Evaluation for Logistic Regression ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.36      0.48        84\n",
      "     Neutral       0.00      0.00      0.00        10\n",
      "    Positive       0.76      0.96      0.85       206\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.50      0.44      0.44       300\n",
      "weighted avg       0.73      0.76      0.72       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAJOCAYAAAD71sLQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYf1JREFUeJzt3Qd4FOXWwPGTUELoNfSOVGmCQgDpiqBI8ypNEJAmTRAVVKSIBAEFQRQvICBFsFAEFEQ6lyIdlSIgRSmCVOmB7Pec9367N5tkIRuys5PN/3efuWRnJ7vvbmbXM2fOeybI4XA4BAAAAIBfBfv36QEAAAAoAnMAAADABgjMAQAAABsgMAcAAABsgMAcAAAAsAECcwAAAMAGCMwBAAAAGyAwBwAAAGyAwBwAAACwAQJzIJEcPHhQHn/8ccmUKZMEBQXJwoULE/Xxjx49ah53+vTpifq4SVnt2rXNkliuXLkiL774ouTKlcu81y+//LIEmjVr1pjXpv8mBt0f9fF0/0TiGDJkiHlPASQ/BOYIKIcPH5auXbtKkSJFJE2aNJIxY0apXr26fPjhh3L9+nWfPnf79u3l559/lnfffVdmzpwplStXlkDxwgsvmEBB38+43kc9KNH7dRkzZozXj3/y5EkTjOzatUv8acSIESbQ7N69u/kbPv/88z59vkKFCslTTz0lSYG+N4l9sOkpyHcuKVOmlLx585r978SJEz59bgCwg5T+HgCQWJYuXSr/+te/JCQkRNq1aycPPvig3Lp1SzZs2CCvvvqq/Prrr/Lvf//bJ8+tweqmTZvkzTfflJ49e/rkOQoWLGieJ1WqVOIPGiRdu3ZNFi9eLM8++6zbfbNnzzYHQjdu3EjQY2tgPnToUBOoVqhQId6/98MPP0hiWrVqlVStWlUGDx4sgapmzZpmP0qdOrXXgfkzzzwjTZs2dVuvBy8tW7Y0n7vEMmzYMClcuLDZnzZv3mwCdv0c//LLL2Y/C3RvvfWWDBgwwN/DAOAHBOYICEeOHDHBgQavGlzlzp3bdV+PHj3k0KFDJnD3lbNnz5p/M2fO7LPn0AyiP4MSDbz07MMXX3wRKzCfM2eOPPnkk/LNN99YMhY9QEibNq3XweW9nDlzRkqXLp1oj3f79m2JiopK9HHej+Dg4ETdj1KkSGGWxNSwYUPXGSctLcqePbu899578u2338ba93zJ4XCYg4PQ0FCx+iBYFwDJD6UsCAijRo0y9cFTp051C8qdihUrJn369HELmN555x0pWrSoCTg1U/vGG2/IzZs34yw10GzdI488YgIaLZP5/PPPXdtoCYYeECjNzGsArb+n9BS88+d71ZCuWLFCatSoYYL79OnTS4kSJcyY7lVjrgcijz76qKRLl878bpMmTWTfvn1xPp8eoOiYdDuthe/QoYMJcuOrdevW8v3338vFixdd67Zu3WpKWfS+mM6fPy/9+/eXsmXLmtekpTAadO3evdu1jdY6P/zww+ZnHY+zjMH5OrWGXM9+bN++3WR7NSB3vi8xa8y1nEj/RjFff4MGDSRLliwmM3+3ums9wNMDOOcYnHXTGrB36tRJcubMaR6/fPnyMmPGDLfHcP59tJRn3Lhxrn1r7969cj/iu6/qAYD+nfPkyWPeozp16pjn1u31b363GnP9+7Vo0cLU1uvry5cvnznQvXTpkrlft7969ap5zc73xvmYnmrMdT+pVauWZMiQwfzd9W+sB3AJofu3s1Qtuv3795ssftasWc24NZjX4D2mPXv2mLFogK2vbfjw4TJt2rRY43Z+3pcvX24eS7f/9NNPzX26z+ucg/z585u/g36n6MGCvu/RzZ07VypVquR63brvaymdU2RkpDk79MADD5gxZ8uWzXzu9fN/t++HxPzOAmBfHJIjIGh5hf7Hp1q1avHaXrNwGmTof9RfeeUV2bJli0RERJiAbsGCBW7bajCr22lgpoHfZ599ZoIS/Y9vmTJlpHnz5ibQ7du3r7Rq1UoaNWpkglBvaJmN/se0XLly5jS+/odXn/c///nPXX/vxx9/NIGuvnb9j7mWKEyYMMFktnfs2BHroECzjVoioK9V758yZYqEhYWZACM+9LV269ZN5s+fLx07djTrNNgqWbKkPPTQQ7G2//33301dspYY6fP+9ddfJtDRIEmDRg0iS5UqZV7z22+/LV26dHEFYdH/lufOnTOvU4PFtm3bmgA5LhoA6YGK/p20tEgzufp8WvKiNeP6fHHRMej9+jfUwE33CZUjRw7znmrwr38PLVPS1/HVV1+ZfUCDtegHfEoDPs2y6mvRv6MGjfcjvvvqwIEDzQFq48aNzYGIHvzov/cqL9JyL91OA7xevXqZ4FzruZcsWWJenx7A6Xuj49BAT1+X0gDREw3Wdf/Qz4eOSz8fO3fulGXLlsV5AHcvzuBZD66if2Z0P9cadC370APTL7/80pTa6JmbZs2ame30tehBiga6OhbdTvd7T6U3Bw4cMJ9jnavSuXNnc4CsB6+6z+pj6foCBQrIxo0bzeOdOnXKHIgpDa71d+vVq+f6TOnfST/Hzv1EP6f693O+n5cvX5Zt27aZz+Njjz1myXcWABtzAEncpUuXHLorN2nSJF7b79q1y2z/4osvuq3v37+/Wb9q1SrXuoIFC5p169atc607c+aMIyQkxPHKK6+41h05csRsN3r0aLfHbN++vXmMmAYPHmy2dxo7dqy5ffbsWY/jdj7HtGnTXOsqVKjgCAsLc5w7d861bvfu3Y7g4GBHu3btYj1fx44d3R6zWbNmjmzZsnl8zuivI126dObnZ555xlGvXj3z8507dxy5cuVyDB06NM734MaNG2abmK9D379hw4a51m3dujXWa3OqVauWuW/SpElx3qdLdMuXLzfbDx8+3PH777870qdP72jatKkjPvRv9eSTT7qtGzdunHm8WbNmudbdunXLER4ebh778uXLrtel22XMmNHsIwl9voTsq6dPn3akTJky1uscMmSI2U7/fk6rV6826/RftXPnTnP7q6++uutY9e8f/XGc9G+mv6+vX128eNGRIUMGR5UqVRzXr1932zYqKuquz+F8rB9//NF8Fv744w/H119/7ciRI4fZZ/S2k+6DZcuWNftY9MevVq2a44EHHnCt69WrlyMoKMi8Tif9vGTNmtVt3NE/78uWLXMb1zvvvGNe/2+//ea2fsCAAY4UKVI4jh8/bm736dPH/P1v377t8TWWL1/+rn/zuL4ffPGdBcCeKGVBkqcZJ6WnjuPju+++M//269fPbb0zSxqzFl1rjp1ZXGcWVbNomg1OLM7a9EWLFsU6Ne6JZuq0i4lmwqJnZTXrrpk35+uMTrPd0enr0my08z2MD814ahnE6dOnTXZa//WUBdWspNY0qzt37pjncpbpaIYwvvRxtMwlPrRlpWY1NQuvGX49le8sR0gIfR81i6yZUCedgNu7d29TPrV27Vq37bUkRPeRxBDffXXlypWm1OGll15y204z4PeiGXGl5RvelDV5olnjf/75x2SxY9ayx7cFYP369c17qGUjmvnVLLeWqOjZDGeJlO57egZIn+vvv/82i+5fmv3X0hxnFxfN0oeHh7tNKtbPS5s2beJ8bj0joo8RnZ4h0c+KZuydz6WLjlP363Xr1rk+x1ryE70sJSbdRrP9Osb4suN3FgDfIDBHkqd1nEr/Ax0fx44dM8Gi1ohGp8GX/kdT749OT1vHpP+BvnDhgiSW5557zpyW19PVWqahJRt6Wv5uQbpznPof3LhKMzRw0CDhbq/FWRrgzWvRUh09CJo3b57pxqK1wzHfSycd/9ixY009rQbXOolPgwSt+XXWL8eHlit4M4FS67w1+NIDl/Hjx5tynYTS91nH7zzAiP4eO++PGdgllvjuq85/Y26n70H08o+46Hg14NPyDv37aFA6ceJEr/4+0TnrwHVeQELp82tw+/XXX5v9Tffl6KUnWqqhEzMHDRpk9qfoi7Ojjs4LcL43ce2fnvbZuP5+GkRrgB/zuTQwj/5cemBUvHhxU3alBxFazqO/F50eMGqJkG6n9ec6L0U/D0ntOwuAb1BjjoAIzLV2WFupeSO+2TtPHSc0MEjoc2iWLTqdZKZZt9WrV5vsl/7HXAPfunXrmvroxOp6cT+vxUkDJM1Ea72rZuC0ZvZuLfY0eNIARSeuaaCoAYZOoovvmQHlbVcMrWd2BkvaWz56ttvXfNHBw9cXm3n//ffNmRc9Y6P7m54N0PplbVXozFJbSWuvnV1ZtGZcJ0fqWRmt/9YzLs59RycWx8xu3yvwTsjfT59Pz0K99tprcf6OBtlKDwD1YFDPPujkV110zoG2b3VOFtYJzHrw4nyv9YBID14nTZpkDsz9/Z0FwL/ImCMg6MRJ/Y+dTvi7F+2gov+hjXkqWScmaibL2WElMWiWKnoHE6eYGS6lAatOGvvggw/MxEi9UJGertdg3dPrUBqsxKTdKjT7qSUAvqBBkga/epZCs/ueaMZTJ95ptxzdTstMNMsY8z1JzMBTzxJo2YuezteJijohUjvHJJS+z7qvxDyQ0PfYeb+vxHdfdf6rmeTotLQjvllSzd5q/2w9QFy/fr0pBdFg0du/kXNSqLcHyncLMvUgQTvqfPTRR2adTnZ2lhTp/hTX4ixt0/cm5vui4lp3t9ekZUuenit6hlrP7OgE3I8//th1wTPtiBL9+fQAVfdRbT36xx9/mPKzux3gWvmdBcC/CMwREDSTpUGoZpz0P1Yx6X8gnS3L9NS4cnZScNKAWGk/7sSi/0HXkoDop6q1NjxmFwWtmY3JWRMbsx2ak7aF1G00Exc90NWASDNxztfpCxpsawZcAyU9nX63oCpmlk7rdWNexdF5ABHXQYy3Xn/9dTl+/Lh5X/Rvqp1ptDOFp/fxXvR91Dp6PYPhpPXc2v1Gs7farcNX4ruv6gGd9r3+5JNP3LZzBrJ3o/ML9PXEDNL1QDH6e6Z/o/j8ffTgS4NiDaZjdoRJaMZWu+JoFl3fB31MzUzrOp07oJ8nT9cVUJpR1wP26FeV1c+blmHFl9ay62NoJjwmfU+c758eCEWn76EG3cr5XsbcRvchze7fbf+08jsLgH9RyoKAoAGwtu3TWm2t/Y1+5U9ta+Zsb6e0B7UGanoVUP2PqgZWP/30kwnk9LS5Bp2JRbPEGihq6zYtD9DJdRo86anv6JMfte5UM5X6H1jNfmkZhmbctIxAT+N7Mnr0aFPPqpPbtDWas12iTui7WwbufmnAodnV+JzJ0Nem2UFtf6hlJRoQOTOe0f9+WiurGVoN6jQIrFKlitf12nqGQd83rTN2tm/UUgIN4rSkRrPn3tKsuwaAuv9oL3UN9PVMgLbA00ApvpOOPdFMqvbVjqlixYpmf4jPvqrzErQdn5akPP300/LEE0+YdolaSqFnTu6W7db3TNtAaktL3S81yNT2iHpQpRNZnbTVnrbn1GBQS8f0b6N/o7hKy7Q0Qw+Sdf6Bnl3RM0c6Ht3/Y/Z/jy+txdYxaitGncSsdej62dCDCG1rqPuUHpRrAP3nn3+6euXrQfusWbNMKYpOhnW2S9Qstwbo8TkToM+tk091f3a2HdQzM7o/676g7Rz1fdbXrI+pJWj62dUzY/p51ANo55wEPZOj+6M+hmbOtVWiPsbdrhhs5XcWAD/zd1sYIDFpO7POnTs7ChUq5EidOrVp21a9enXHhAkT3NqqRUZGmhZ/hQsXdqRKlcqRP39+x8CBA922uVs7u5ht+jy1S1Q//PCD48EHHzTjKVGihGm7F7Md2sqVK027xzx58pjt9N9WrVq5tWeLq12i0tZy+hpDQ0NNq7bGjRs79u7d67aN8/litmOM2eouPu0SPfHULlFbtOXOnduMT8e5adOmONscLlq0yFG6dGnT9i/669TtypQpE+dzRn8cbVuof6+HHnrI/H2j69u3r2khqc99N57+3n/99ZejQ4cOjuzZs5u/j7bpi/l3uNs+cLfn09+Ja+nUqZNX+6q26Bs0aJBpX6nvdd26dR379u0z7TC7devmsV2itpTUNppFixZ1pEmTxrQRrFOnjtmvotu/f7+jZs2a5rGjt2D0tA99++23pnWhc7985JFHHF988cVd3w/nY2n7zJi07aaOURdnO8LDhw+btqD6mvW9yZs3r+Opp54yLRaj01aJjz76qGkZmC9fPkdERIRj/Pjx5rm01WT0v4enVob//POPed+LFStm9gHdF/T1jRkzxrTPVPq8jz/+uGlhqtsUKFDA0bVrV8epU6dcj6NtPPW9yJw5s3lvSpYs6Xj33Xddj6Fifj/44jsLgD0F6f/5++AAAJD4NLuq2WrNyL/55pv+Ho6t6ARkPROiteOJNbkaAO4XNeYAEAC0jCkmZ02ylk4kZzHfG63z1nIdLYUhKAdgJ9SYA0AA0MmpWn+tEwV1QuGGDRtM1w+djKk98pMznYOhByda56116NolSCe96rwDALATAnMACADa/UM7s+gEVw06nRNC45pYmtzowYpOsNTJkzrZUycGa3CuPcUBwE6oMQcAAABsgBpzAAAAwAYIzAEAAAAbIDAHAAAAbCAgJ3/+9tc1fw8B8LsC2dL6ewiA320+fN7fQwD8rnaJrGInoRU9X+k2sVzf+ZEkRWTMAQAAABsIyIw5AAAAbCqIvLAnvDMAAACADZAxBwAAgHWCgvw9AtsiYw4AAADYABlzAAAAWIcac494ZwAAAAAbIGMOAAAA61Bj7hEZcwAAAMAGyJgDAADAOtSYe8Q7AwAAANgAGXMAAABYhxpzj8iYAwAAADZAxhwAAADWocbcI94ZAAAAwAbImAMAAMA61Jh7RMYcAAAAsAEy5gAAALAONeYe8c4AAAAANkDGHAAAANahxtwjMuYAAACADZAxBwAAgHWoMfeIdwYAAACwATLmAAAAsA415h6RMQcAAABsgIw5AAAArEONuUe8MwAAAIANkDEHAACAdciYe8Q7AwAAANgAGXMAAABYJ5iuLJ6QMQcAAABsgIw5AAAArEONuUe8MwAAAIANkDEHAACAdbjyp0dkzAEAAAAbIGMOAAAA61Bj7hHvDAAAAGADZMwBAABgHWrMPSJjDgAAANgAGXMAAABYhxpzj3hnAAAAABsgYw4AAADrUGPuERlzAAAAwAbImAMAAMA61Jh7xDsDAAAA2AAZcwAAAFiHGnOPyJgDAAAANkDGHAAAANahxtwj3hkAAADABsiYAwAAwDrUmHtExhwAAACwATLmAAAAsA415h7xzgAAAAA2QGAOAAAAazPmvl68sG7dOmncuLHkyZNHgoKCZOHChW7367q4ltGjR7u2KVSoUKz7R44cKd4iMAcAAECydfXqVSlfvrxMnDgxzvtPnTrltnz22Wcm8G7RooXbdsOGDXPbrlevXl6PhRpzAAAAJNuuLA0bNjSLJ7ly5XK7vWjRIqlTp44UKVLEbX2GDBlibZtkM+br16+Xtm3bSnh4uJw4ccKsmzlzpmzYsMHfQwMAAECAlrJ446+//pKlS5dKp06dYt2npSvZsmWTihUrmjKX27dvS5IMzL/55htp0KCBhIaGys6dO+XmzZtm/aVLl2TEiBH+Hh4AAACSkJs3b8rly5fdFmd8eT9mzJhhMuPNmzd3W9+7d2+ZO3eurF69Wrp27Wri19deey1pBubDhw+XSZMmyeTJkyVVqlSu9dWrV5cdO3b4dWwAAABI5FIWHy8RERGSKVMmt0XX3S+tL2/Tpo2kSZPGbX2/fv2kdu3aUq5cOenWrZu8//77MmHCBK8PBmxRY37gwAGpWbNmrPX6Jl68eNEvYwIAAEDSNHDgQBMsRxcSEnLfZdcas86bN++e21apUsWUshw9elRKlCiRtAJzLZQ/dOiQaTUTndaXxyysBwAAQBJmwQWGQkJC7jsQj2nq1KlSqVIl08HlXnbt2iXBwcESFhbm1XPYIjDv3Lmz9OnTx9V+5uTJk7Jp0ybp37+/DBo0yN/DAwAAQIC6cuWKSRA7HTlyxATWWbNmlQIFCph1WqP+1VdfmRKVmDRm3bJli+nUovXnertv376mqUmWLFmSXmA+YMAAiYqKknr16sm1a9dMWYse5WhgnpAekAAAALApm7VL3LZtmwmqnZwlMO3bt5fp06ebn3Vip8PhkFatWsX6fY1Z9f4hQ4aYmvLChQubwDxmKU18BDn0WWzi1q1b5ohFj1xKly4t6dOnT9Dj/PbXtUQfG5DUFMiW1t9DAPxu8+Hz/h4C4He1S2QVOwltPtXnz3F9fux2hkmBLTLms2bNMm1n0qZNawJyAAAABCYtW4aN2yVqul+L41u3bi3fffed3Llzx99DAgAAAJJfYH7q1ClTm6NHUM8++6zkzp1bevToIRs3bvT30AAAAJCINN7z9ZJU2SIwT5kypTz11FMye/ZsOXPmjIwdO9b0fdRC/KJFi/p7eAAAAEDyqDGPTuvMGzRoIBcuXJBjx47Jvn37/D0kAAAAJJakm9BOHhlzpW0SNWPeqFEjyZs3r4wbN06aNWsmv/76q7+HBgAAACSPjHnLli1lyZIlJluuNeZ6UaHw8HB/DwsAAACJLCnXgCeLwDxFihTy5ZdfmhIW/RkAAABIbmwRmGsJCwAAAAIfGXMbBubjx4+XLl26SJo0aczPd9O7d2/LxgUAAAD4Q5DD4XD444kLFy4s27Ztk2zZspmf73ZU9fvvv3v12L/9dS0RRggkbQWypfX3EAC/23z4vL+HAPhd7RJZxU4ytvzc589xeW47SYr8ljE/cuRInD8DAAAAyZEt2iUOGzbMtEuM6fr16+Y+AAAABAau/GnDUpbotBPLqVOnJCwszG39uXPnzLo7d+549XiUsvjedwu/lO8Xfi1/nT5pbhcoXERatu8ilavWMLdv3bwpUyd+IOtXLZfIyFtS8eFw6d7vDcmSNZufR558UMriP3PnzJYZ06bK33+fleIlSsqANwZJ2XLl/D2sZIlSFt9bPGeKLJk71W1dzrwFZNgn89zWabgxYWg/+XXHZun+xkipULWWxSNNvuxWypKp1UyfP8elL56XpMgWXVn0wxrX0c3u3bsla1Z77Uz4r+w5ckr7rr0kT74Cokd2K5ctlnff6Cvjps6VgoWLypSPxsjWTRvk9aGjJF369DJp3EiJeOsVGfXxdH8PHfCpZd9/J2NGRchbg4dK2bLlZfbMGdK9aydZtGSZmVMDBKI8BYrIy+/8r5FDXK2PV347N0lnMpGI2A3sWcqSJUsWE3jrB7V48eLmZ+eSKVMmeeyxx8wFh2A/j1SvJZXDH5U8+QtK3vwFpV3nnpImNK0c+HWPXL3yj6xYulBe7NlPyld6RIqVKC19BgyVfb/slv2/7vH30AGfmjljmjR/5llp2qyFFC1WzATo2n1q4fxv/D00wGeCU6SQTFmyuZb0GTO73f/H77/JioVfSLveb/ptjEBS4NeM+bhx40y2vGPHjjJ06FATjDulTp1aChUqxBVAkwAtNfrPmhVy48Z1KflgOTl0YJ/cvn1byleq6tomf8HCkiNnLhOYlyzDKX0Epshbt2Tf3l+lU+eurnXBwcFStWo12bN7p1/HBvjSmZN/yGsvNJZUqVJLkZIPSrN23SVrjlzmvls3b8jU9wdLq679TdAOcObEpoF5+/btzb/aLrFatWqSKlUqfw4HXjp6+KC8+lJ7uXXrloSGhsqbw9+XAoWKyu8Hf5OUqVJJ+gwZ3LbPnCWbXDx3zm/jBXztwsUL5kA1ZsmK3j5yxLu2r0BSUbhEGXmhz1uSM29BuXThb1NvPnpAdxk8YZakSZtOvpwyToqULCsVqtb091AB27NFjXmtWv+bAHLjxg0T6EWXMWNGj7978+ZNs0R36+YdSR0S4oORIrq8BQrJh1PnyrWrV+Q/a36UsSPelogJU/w9LACAhR6s9L8z2/kKF5PCxcvIwBebybYNKyVDpixyYM92eXPcDL+OEfZCxtzm7RK1VWLPnj1NB5Z06dKZ2vPoy91ERESYEpjoy6fjx1g29uRMz3Do5E+tIW/ftbcULlZcvv3qC9N55XZkpFz55x+37S9eOCeZmfyGAJYlcxYz6U07SkWnt7Nnz+63cQFWSps+g+TMU0DOnvpT9u/ZJmdPn5C+rR6X7k1rmEVNGvmGvP/GS/4eKmA7tsiYv/rqq7J69Wr55JNP5Pnnn5eJEyfKiRMn5NNPP5WRI0fe9XcHDhwo/fr1c1t3/KJ37RWROBxRDtMasViJUpIyZUrZvX2LVK9d39z35/Gjcvav09SXI6ClSp1aSpUuI1s2b5K69f6770dFRcmWLZukZau2/h4eYIkb16/J2dN/StU6T0ilGvWkxuNPu90/rFdbebZTHyn38H+DdCQ/ZMxtHpgvXrxYPv/8c6ldu7Z06NBBHn30USlWrJgULFhQZs+eLW3atPH4uyEhIWaJLvV1+pj72oxPx0ulKtUlR87ccv3aVVn74/fy865tMnTMx5IufQZ57MmmMnXi+5IhYyZJmy6dfDruPROUE5gj0D3fvoMMeuN1KVPmQXmwbDmZNXOGuVha02bN/T00wCe+/my8lHukhmTNkVsunT9r+poHB6eQh2s+ZkpZ4prwmTVHTsmeK49fxgvYmS0C8/Pnz0uRIkVc9eR6W9WoUUO6d+/u59EhLpcunJexIwbJ+XN/S7p06aVQ0QdMUF7x4f92YnmxZ38JCgqWiEH9TRb9oYerSfd+A/09bMDnnmjYSC6cPy8ffzTeXGCoRMlS8vGnUyQbpSwIUBfOnZUpYwbL1cuXJH2mzFKsdHkZMHqyCcqBuJAxt/mVP8uVKycTJkwwk0Dr168vFSpUkDFjxsj48eNl1KhR8ueff3r1eFz5E+DKn4Diyp+A/a78ma3dFz5/jnOft5KkyBaTP7V8Ra/yqQYMGGBqzPWCHH379jX15wAAAAgQQRYsSZQtSlk0AHfSjPn+/ftl+/btps5cs+kAAABAoLNFYB6TTvrUBQAAAIGFGnObB+ZaS+7pD6clLZo5r1mzpukPDAAAAAQiWwTmY8eOlbNnz5oLDTkvKHThwgVJmzatpE+fXs6cOWO6tmiv8/z58/t7uAAAAEggMuY2n/w5YsQIefjhh+XgwYPmCnm6/Pbbb1KlShX58MMP5fjx45IrVy63WnQAAAAgkNgiY/7WW2/JN998I0WLFnWt0/IVbZnYokUL+f33303bRP0ZAAAASRcZc5tnzE+dOiW3b9+OtV7XnT592vycJ08e+eeff/wwOgAAACCZBOZ16tSRrl27ys6dO13r9Ge96mfdunXN7Z9//lkKFy7sx1ECAADgvtHH3N6B+dSpUyVr1qxSqVIlCQkJMUvlypXNOr1P6STQ999/399DBQAAAAK3xlwndq5YscJcWEgnfaoSJUqYJXpWHQAAAEkbNeY2D8ydtCWi/rF0EmjKlLYaGgAAABD4pSzav7xTp06mb3mZMmVMe0TVq1cvGTlypL+HBwAAgESiSVhfL0mVLQLzgQMHyu7du2XNmjXmSp9O9evXl3nz5vl1bAAAAIAVbFEvsnDhQhOAV61a1e0oR7Pnhw8f9uvYAAAAkHiSckY7WWTMz549K2FhYbHWX716lT8eAAAAkgVbBObaGnHp0qWu285gfMqUKRIeHu7HkQEAACAxUWNu81KWESNGSMOGDWXv3r3map8ffvih+Xnjxo2ydu1afw8PAAAASB4Z8xo1asiuXbtMUF62bFn54YcfTGnLpk2bzEWHAAAAECC48qe9M+ZKe5dPnjzZ38MAAAAAkl9gHhwcfM86IL1fM+kAAABI+pJyDXhAB+YLFizweJ+WsYwfP16ioqIsHRMAAACQ7ALzJk2axFp34MABGTBggCxevFjatGkjw4YN88vYAAAAkPjImNt88qc6efKkdO7c2Uz+1NIVnQw6Y8YMKViwoL+HBgAAAAT+5M9Lly6ZdokTJkyQChUqyMqVK+XRRx/197AAAADgA2TMbRqYjxo1St577z3JlSuXfPHFF3GWtgAAAADJQZDD4XD4sytLaGio1K9fX1KkSOFxu/nz53v1uL/9dS0RRgckbQWypfX3EAC/23z4vL+HAPhd7RJZxU7y91zk8+f446Okmez1a8a8Xbt2nM4AAAAA/B2YT58+3Z9PDwAAAIuRlE0CXVkAAAAAq61bt04aN24sefLkMQcNCxcudLv/hRdeMOujL0888YTbNufPnzdtvjNmzCiZM2eWTp06yZUrV7weC4E5AAAALBMzyPXF4o2rV69K+fLlZeLEiR630UD81KlTrkWblkSnQfmvv/4qK1askCVLlphgv0uXLpLk2iUCAAAA/tKwYUOz3E1ISIjpIhiXffv2ybJly2Tr1q1SuXJls07bgDdq1EjGjBljMvHxRcYcAAAAyTZjHh9r1qyRsLAwKVGihHTv3l3OnTvnum/Tpk2mfMUZlCvtOKjdB7ds2SLeIGMOAACAgJr8efPmTbPEzHrr4i0tY2nevLkULlxYDh8+LG+88YbJsGtAru2+T58+bYL26FKmTClZs2Y193mDjDkAAAACSkREhGTKlMlt0XUJ0bJlS3n66aelbNmy0rRpU1NDrmUrmkVPbGTMAQAAYB0LuiUOHDhQ+vXr57YuIdnyuBQpUkSyZ88uhw4dknr16pna8zNnzrhtc/v2bdOpxVNduicE5gAAAAgoIQksW4mPP//809SY586d29wODw+Xixcvyvbt26VSpUpm3apVqyQqKkqqVKni1WMTmAMAACDZXmDoypUrJvvtdOTIEdm1a5epEddl6NCh0qJFC5P91hrz1157TYoVKyYNGjQw25cqVcrUoXfu3FkmTZokkZGR0rNnT1MC401HFkWNOQAAAJKtbdu2ScWKFc2itARGf3777bfN5M49e/aYGvPixYubCwdpVnz9+vVuGfnZs2dLyZIlTWmLtkmsUaOG/Pvf//Z6LGTMAQAAkGwz5rVr1xaHw+Hx/uXLl9/zMTSzPmfOnPseCxlzAAAAwAbImAMAAMAyNkuY2woZcwAAAMAGyJgDAAAg2daY2wkZcwAAAMAGyJgDAADAMiTMPSNjDgAAANgAGXMAAABYhhpzz8iYAwAAADZAxhwAAACWIWHuGRlzAAAAwAbImAMAAMAywcGkzD0hYw4AAADYABlzAAAAWIYac8/ImAMAAAA2QMYcAAAAlqGPuWdkzAEAAAAbIGMOAAAAy5Aw94yMOQAAAGADZMwBAABgGWrMPSNjDgAAANgAGXMAAABYhoy5Z2TMAQAAABsgYw4AAADLkDD3jIw5AAAAYANkzAEAAGAZasw9I2MOAAAA2AAZcwAAAFiGhLlnZMwBAAAAGyBjDgAAAMtQY+4ZGXMAAADABsiYAwAAwDIkzD0jYw4AAADYABlzAAAAWIYac8/ImAMAAAA2QMYcAAAAliFh7hkZcwAAAMAGyJgDAADAMtSYe0bGHAAAALCBgMyY58sa6u8hAABsoEKBTP4eAoAYSJh7RsYcAAAAsIGAzJgDAADAnqgx94yMOQAAAGADZMwBAABgGRLmnpExBwAAAGyAjDkAAAAsQ425Z2TMAQAAABsgYw4AAADLkDD3jIw5AAAAYANkzAEAAGAZasw9I2MOAAAA2AAZcwAAAFiGjLlnZMwBAAAAGyAwBwAAgGU0Ye7rxRvr1q2Txo0bS548eUw2f+HCha77IiMj5fXXX5eyZctKunTpzDbt2rWTkydPuj1GoUKFzO9GX0aOHCneIjAHAABAsnX16lUpX768TJw4MdZ9165dkx07dsigQYPMv/Pnz5cDBw7I008/HWvbYcOGyalTp1xLr169vB4LNeYAAABItjXmDRs2NEtcMmXKJCtWrHBb99FHH8kjjzwix48flwIFCrjWZ8iQQXLlynVfYyFjDgAAgIBy8+ZNuXz5stui6xLDpUuXzMFF5syZ3dZr6Uq2bNmkYsWKMnr0aLl9+7bXj01gDgAAgICqMY+IiDDZ7uiLrrtfN27cMDXnrVq1kowZM7rW9+7dW+bOnSurV6+Wrl27yogRI+S1117z/r1xOBwOCTDXIgPuJQFeC7bZqULAH25E3vH3EAC/yxyaQuykzocbff4cy7pVipUhDwkJMcvdaCZ8wYIF0rRp01j36UTQFi1ayJ9//ilr1qxxC8xj+uyzz0yAfuXKlXs+Z3TUmAMAACCgasxD4hGEe0OD8meffVaOHTsmq1atumtQrqpUqWJKWY4ePSolSpSI9/MQmAMAAMAySe2EbuT/B+UHDx40pSpaR34vu3btkuDgYAkLC/PquQjMAQAAkGxduXJFDh065Lp95MgRE1hnzZpVcufOLc8884xplbhkyRK5c+eOnD592myn96dOnVo2bdokW7ZskTp16pjOLHq7b9++0rZtW8mSJYtXY6HGHAhQ1JgD1JgDdqwxf+yjzT5/jhU9q8Z7W60X16A6pvbt28uQIUOkcOHCcf6eZs9r165tgvaXXnpJ9u/fb+radfvnn39e+vXr53U5DRlzAAAAJFu1a9eWu+Wp75XDfuihh2Tz5sQ52CAwBwAAgGU4oesZfcwBAAAAGyBjDgAAgIBql5hUkTEHAAAAbICMOQAAACwTTMLcIzLmAAAAgA2QMQcAAIBlqDH3jIw5AAAAYANkzAEAAGAZEuaekTEHAAAAbICMOQAAACwTJKTMPSFjDgAAANgAGXMAAABYhj7mnpExBwAAAGyAjDkAAAAsQx9zz8iYAwAAADZAxhwAAACWIWHuGRlzAAAAwAbImAMAAMAywaTMPSJjDgAAANgAGXMAAABYhoS5Z2TMAQAAABsgYw4AAADL0MfcMzLmAAAAgA2QMQcAAIBlSJjfZ2C+Z88eia9y5crFe1sAAAAAXgTmFSpUMPVADocjzvud9+m/d+7cic9DAgAAIBmij/l9BuZHjhyJz2YAAAAAfBmYFyxYMKGPDwAAALiQL0/kriwzZ86U6tWrS548eeTYsWNm3bhx42TRokUJeTgAAAAg2fM6MP/kk0+kX79+0qhRI7l48aKrpjxz5swmOAcAAAA80TmJvl6STWA+YcIEmTx5srz55puSIkUK1/rKlSvLzz//nNjjAwAAAJIFr/uY60TQihUrxlofEhIiV69eTaxxAQAAIAAFJ92Etv0y5oULF5Zdu3bFWr9s2TIpVapUYo0LAAAASFa8zphrfXmPHj3kxo0bpnf5Tz/9JF988YVERETIlClTfDNKAAAABISkXANuu8D8xRdflNDQUHnrrbfk2rVr0rp1a9Od5cMPP5SWLVv6ZpQAAABAgAtyeLqcZzxoYH7lyhUJCwsTO7kWmeCXBAQMrqwGiNyI5GrUQObQ/zXrsIPnZ+/2+XPMbFNekkXG3OnMmTNy4MAB1ymJHDlyePX7ly9fjve2GTNm9Hp8AAAAQEAH5v/884+89NJLpq48KirKrNO2ic8995xMnDhRMmXKFK/H0b7n96ox0mS+buPslQ4AAICkjRrzRK4x37lzpyxdulTCw8PNuk2bNkmfPn2ka9euMnfu3Hg9zurVq719agAAACBgeV1jni5dOlm+fLnUqFHDbf369evliSeesEUvc2rMAWrMAUWNOWC/GvMXvtjj8+eY3qqcJIuMebZs2eIsV9F1WbJkua/B6GTS48ePy61bt9zWlyuXNN9cAAAAwGeBubZJ1F7mM2fOlFy5cpl1p0+flldffVUGDRokCXH27Fnp0KGDfP/993HeT405AABAYKDG/D4D84oVK7q9iQcPHpQCBQqYRWmWOyQkxATYWmfurZdfflkuXrwoW7Zskdq1a8uCBQvkr7/+kuHDh8v777/v9eMBAAAAARmYN23a1KeDWLVqlSxatEgqV64swcHBUrBgQXnsscdMm0S9ouiTTz7p0+cHAACANciX32dgPnjwYPElnTDqvEiR1qlr5r148eJStmxZ2bFjh0+fGwAAALCDYLGBEiVKuC5WVL58efn000/lxIkTMmnSJMmdO7e/hwcAAIBE7Brm6yXZTP7UiZhjx46VL7/8Ms4OKufPn/d6ENoD/dSpU67svLZdnD17tqROnVqmT5/u9eMBAAAAAR+YDx06VKZMmSKvvPKK6dDy5ptvytGjR2XhwoXy9ttvJ2gQbdu2df1cqVIlOXbsmOzfv99MLs2ePXuCHhMAAAD2k4QT2vYrZdFM9uTJk01gnjJlSmnVqpUJ1DUo37x5s9cDiIyMlKJFi8q+fftc69KmTSsPPfQQQTkAAACSDa8Dc+1ZrpMyVfr06eXSpUvm56eeekqWLl3q9QBSpUolN27c8Pr3AAAAkPRoC25fL8kmMM+XL5+rHlwz3T/88IP5eevWraaXeUL06NFD3nvvPbl9+3aCfh8AAABI6rwOzJs1ayYrV640P/fq1ctc7fOBBx6Qdu3aSceOHRM0CA3q58+fb2rKGzRoIM2bN3dbAAAAEBg0oe3rxRvr1q2Txo0bS548eUy2XedNRudwOEzJtnYKDA0Nlfr165uLbcZsftKmTRtzDZ7MmTNLp06d5MqVK+LzyZ8jR450/fzcc8+ZiwFt3LjRBOf6ohJCX0CLFi0S9LsAAADA/VxPR9t1a4I5roTwqFGjZPz48TJjxgwpXLiwSUprInnv3r2SJk0as40G5VpRsmLFCjN/skOHDtKlSxeZM2eOV2MJcuhhQCI4c+aMmQT6xhtviL9di0yUlwQvTZ38qaz6cYUcPfK7hKRJI+UrVJQ+fV+RQoWL+HtoyVJS7uOa1M2dM1tmTJsqf/99VoqXKCkD3hgkZcuV8/ewkqUbkXf8PYRkR9sqT540UZYtXSznz/0t2XOEyZNPN5WOnbsl6drfpCxzaAqxk+7f7PX5c3zSonSCfk/30QULFriueq9hsmbStelJ//79zTqdX5kzZ07T0rtly5amgUnp0qVNBYhexV4tW7ZMGjVqJH/++af5fcsvMKRHCXoEkRB169aVixcvxlp/+fJlcx+Shh3btspzrVrL53PmySf//kxuR96W7l1elOvXrvl7aIBlln3/nYwZFSFdX+ohc79aICVKlJTuXTvJuXPn/D00wBIzp02R+V/Nlf4D3pK585dIjz79ZNb0qfLlF7P8PTTAa0eOHDGNT7R8xSlTpkxSpUoV2bRpk7mt/2r1hzMoV7p9cHCwbNmyxbelLL6wZs2aWBcqUtqtZf369X4ZE7w38dMpbreHvhsh9WpWk717f5VKlR/227gAK82cMU2aP/OsNG323/K8twYPlXXr1sjC+d9Ip85d/D08wOf27N4lNWvXlRo1a5nbefLmlR+WfSd7f/nZ30ODTVhx4uTmzZtmiU6blHjbqESDcqUZ8uj0tvM+/TcsLMztfm0pnjVrVtc2lmfME2LPnj1mUVqn47yty86dO2Xq1KmSN29efw4R9+HKlX9cR5ZAchB565bs2/urVA2v5lqnGZOqVavJnt07/To2wCrlyleQbVs2y/FjR83t3w7sl907d0h49Uf9PTQkIxERESb+iL7oOrvza8a8QoUKrn6TcZWs6MzXCRMm+GVsuD9RUVEyZuQIqVDxISn2QHF/DwewxIWLF0x9bbZs2dzW6+0jR37327gAK7Xr2NlMpnu26ZMSnCKFRN25I9169pEnnkxYgwgEHivmGgwcOFD69evnti4hbb1z5cpl/v3rr79MVxYnva1xrHMbnWsZnbYA104tzt9P9MA85ouL6ezZs5KQuh0tqi9SpIj89NNPkiNHDtd9qVOnNqcFUqRI4fWpijvBqRPcUx2JI2L4MDl06KBM+9y72cgAgKTtxx+WybLvlsiwiNFSpGgxkzEfOzpCcvz/JFDACiEJKFuJi3Zh0eBaW4U7A3GdA6m14927dze3w8PDzVzJ7du3S6VKlcy6VatWmSSl1qL7JDDX0pJ7qVmzpldPrq0WlQ48ofS0xNChQ93WvfHW2/Lm20MS/Ji4PyPfHSbr166RqTNmSU4vjxSBpCxL5iwmmRBzoqfezp49u9/GBVhpwtgx0q7Di/L4E43MbT1revrUSZnx2WQCc/i/jjoO2m/80KFDbonjXbt2mRpxvcbOyy+/LMOHDzetwZ3tErXTirNzS6lSpeSJJ56Qzp07y6RJk0y7xJ49e5qOLd50ZPEqMF+9erX4yueff37X+/XiRd6cqtCMOaynZz/eG/GOrFr5o0ye9rnkzZfP30MCLJUqdWopVbqMbNm8SerWq+9KPGzZsklatmrr7+EBlrhx47qZWxGd3r6fJBwCi93aZm7btk3q1Knjuu2MK9u3b29aIr722mumPEv7kmtmvEaNGqYdorOHuZo9e7YJxuvVq2f2d70+j/Y+91ai9TG/H1myZHG7rUca165dM+UsadOmNTU63qCPuX+MeGeofP/dEhk7fqIUKlzYtT59+gxuOy+sQR9z/7VLHPTG6zJo8DB5sGw5mTVzhvyw/HtZtPh7yUbW3HL0MbfesEFvyE9bNsmAt4b8fynLPol4Z7A0btJcer78ir+HlyzZrY9574X7ff4c45uWlKTIFoF5XPRSp1q78+qrr5qrK3mDwNw/Kj4Y94dg6PAR8nTT2FfSgm8RmPvPF7NnuS4wVKJkKXn9jbekXLny/h5WskRgbj3NLH46cbysXf2jXDh/3lxgSMtaOnXtLqlScUbbH+wWmL+8yPeB+bgmBOY+ObXQtm1b2b/fuz8ggTlAYA4oAnOAwDwpscUFhjzR5uwnT5709zAAAACQSILJG9k7MP/222/dbmsS/9SpU/LRRx9J9erV/TYuAAAAwNaB+fr16+XTTz+Vw4cPy9dff22uzjlz5kzTQkZnqnrL2W4m+mxd7WmuFx16//33EzJEAAAA2JDdurIk6VaS33zzjZmMqVfl1N7mzov7XLp0SUaMGJGgQWgLpeiLXjnv9OnTMmfOHLerLAEAAACByuvAXBusa/P0yZMnS6pUqVzrteRkx44d9zWYW7duyYEDB8xlTAEAABCYNea+XpJNYK6Bc1xX+MyUKZNpup4Q2rO8Y8eOpmd5mTJl5Pjx42Z9r169ZOTIkQl6TAAAACCgA/NcuXK5XbbUacOGDVKkSJEEDUKv3rlnzx5Zs2aN24Vo6tevL/PmzUvQYwIAAMB+tMTc10uyCcw7d+4sffr0kS1btpjifW1nqJch7d+/v7kgUEIsXLjQdGDRiaPRJwRo9lwnmAIAAACBzuuuLAMGDDATNOvVq2dKULSsJSQkxATmWnqSEGfPnpWwsLA4rx7GzF0AAIDAwQXwEjFjroHym2++KefPn5dffvlFNm/ebALrd955RxKqcuXKsnTpUrfnUFOmTJHw8PAEPy4AAAAQ8BcYSp06tZQuXTpRBqFtFhs2bCh79+41HVk+/PBD8/PGjRtl7dq1ifIcAAAASIJZ4WTE68C8Tp06dy0vWbVqldeD0NryXbt2mQ4sZcuWlR9++EEeeugh2bRpk7kNAAAABDqvA/MKFSq43Y6MjDRBtZa1tG/fPsEDKVq0qOmNDgAAgMBFiXkiBuZjx46Nc/2QIUPkypUrXj1WcHDwPSd36v1ccAgAAACBLsE15jG1bdtWHnnkERkzZky8f2fBggUe79MylvHjx5sOMAAAAAgMdGWxIDDXQDr6xYHio0mTJnFeWVRbMi5evFjatGkjw4YNS6whAgAAAIETmDdv3tzttsPhkFOnTsm2bdtk0KBBCR6IXqho8ODBMmPGDGnQoIGpW3/wwQcT/HgAAACwHxLmiRiYZ8qUKVadeIkSJUxm+/HHH/f24eTSpUumXeKECRPMxNKVK1fKo48+6vXjAAAAAMkmML9z54506NDBtDDMkiXLfT/5qFGj5L333pNcuXLJF198EWdpCwAAAAJHMBlzj4IcWoviBa0j37dvnxQuXPi+n1yz7aGhoVK/fn1JkSKFx+3mz5/v1eNei/TqJQEBick1gMiNyDv+HgLgd5lDPcdY/jDkh4O+f47HH5BkUcqidd+///57ogTm7dq1u2e7RAAAAAQOEkeJGJgPHz5c+vfvL++8845UqlRJ0qVL53Z/xowZ4/1Y06dP9/bpAQAAgOQdmOvkzldeeUUaNWpkbj/99NNu2W6tiNHbWocOAAAAxIWEeSIE5kOHDpVu3brJ6tWr4/srAAAAABI7MHfOEa1Vq1Z8fwUAAABwQ1cWz4LFC0zUBAAAAGww+bN48eL3DM7Pnz9/v2MCAABAgAoSEr2JEphrnXnMK38CAAAAsDgwb9mypYSFhSXC0wIAACA5osY8EWrMqS8HAAAAfMfrriwAAABAQpExT4TAPCoqKr6bAgAAAPBljTkAAABwPyiPTqQ+5gAAAAB8g4w5AAAALEONuWdkzAEAAAAbIGMOAAAAy1Bi7hkZcwAAAMAGyJgDAADAMsGkzD0iYw4AAADYABlzAAAAWIauLJ6RMQcAAABsgIw5AAAALEOJuWdkzAEAAAAbIGMOAAAAywQLKXNPyJgDAAAANkDGHAAAAJahxtwzMuYAAACADZAxBwAAgGXoY+4ZGXMAAADABsiYAwAAwDLBFJl7RMYcAAAAyVahQoUkKCgo1tKjRw9zf+3atWPd161bN5+MhYw5AAAALGO3hPnWrVvlzp07rtu//PKLPPbYY/Kvf/3Lta5z584ybNgw1+20adP6ZCwE5gAAAEi2cuTI4XZ75MiRUrRoUalVq5ZbIJ4rVy6fj4VSFgAAAFhaY+7rJaFu3bols2bNko4dO5qSFafZs2dL9uzZ5cEHH5SBAwfKtWvXxBfImAMAACCg3Lx50yzRhYSEmOVuFi5cKBcvXpQXXnjBta5169ZSsGBByZMnj+zZs0def/11OXDggMyfPz/Rxx3kcDgcEmCuRQbcSwK8xqx3QORG5P/qRoHkKnNoCrGTz7Ye9/lzHF/6mQwdOtRt3eDBg2XIkCF3/b0GDRpI6tSpZfHixR63WbVqldSrV08OHTpkSl4SExlzAAAABJSBAwdKv3793NbdK1t+7Ngx+fHHH++ZCa9SpYr5l8AcAAAASZoVExxD4lG2EtO0adMkLCxMnnzyybtut2vXLvNv7ty5JbERmAMAACBZi4qKMoF5+/btJWXK/4XHhw8fljlz5kijRo0kW7Zspsa8b9++UrNmTSlXrlyij4PAHAAAAJaJ3u3ELn788Uc5fvy46cYSndab633jxo2Tq1evSv78+aVFixby1ltv+WQcTP4EAhSTPwEmfwJ2nPw5Y9sfPn+O9pXzS1JExhwAAACWIW3kGYE5AAAALMMZXc+48icAAABgA2TMAQAAYBny5Z6RMQcAAABsgIw5AAAALEOJuWdkzAEAAAAbIGMOAACAZH2BIbsgYw4AAADYABlzAAAAWIassGe8NwAAAIANkDEHAACAZagx94yMOQAAAGADZMwBAABgGfLlnpExBwAAAGyAjDkAAAAsQ425Z2TMAQAAABsIyIz5rdtR/h4C4HdpUqXw9xAAv8tdrY+/hwD43fWdH4mdkBX2jPcGAAAAsIGAzJgDAADAnqgx94yMOQAAAGADZMwBAABgGfLlnpExBwAAAGyAjDkAAAAsQ4m5Z2TMAQAAABsgYw4AAADLBFNl7hEZcwAAAMAGyJgDAADAMtSYe0bGHAAAALABMuYAAACwTBA15h6RMQcAAABsgIw5AAAALEONuWdkzAEAAAAbIGMOAAAAy9DH3DMy5gAAAIANkDEHAACAZagx94yMOQAAAGADZMwBAABgGTLmnpExBwAAAGyAjDkAAAAsw5U/PSNjDgAAANgAGXMAAABYJpiEuUdkzAEAAAAbIGMOAAAAy1Bj7hkZcwAAAMAGyJgDAADAMvQx94yMOQAAAGADZMwBAABgGWrMPSNjDgAAANgAGXMAAABYhj7mnpExBwAAAGyAjDkAAAAsQ425Z2TMAQAAABsgMAcAAIClfcx9vXhjyJAhEhQU5LaULFnSdf+NGzekR48eki1bNkmfPr20aNFC/vrrL/EFAnMAAAAka2XKlJFTp065lg0bNrju69u3ryxevFi++uorWbt2rZw8eVKaN2/uk3FQYw4AAADL2LHCPGXKlJIrV65Y6y9duiRTp06VOXPmSN26dc26adOmSalSpWTz5s1StWrVRB0HGXMAAAAElJs3b8rly5fdFl3nycGDByVPnjxSpEgRadOmjRw/ftys3759u0RGRkr9+vVd22qZS4ECBWTTpk2JPm4CcwAAAFgmOCjI50tERIRkypTJbdF1calSpYpMnz5dli1bJp988okcOXJEHn30Ufnnn3/k9OnTkjp1asmcObPb7+TMmdPcl9goZQEAAEBAGThwoPTr189tXUhISJzbNmzY0PVzuXLlTKBesGBB+fLLLyU0NFSsRGAOAACAgKoxDwkJ8RiI34tmx4sXLy6HDh2Sxx57TG7duiUXL150y5prV5a4atLvF6UsAAAAwP+7cuWKHD58WHLnzi2VKlWSVKlSycqVK513y4EDB0wNenh4uCQ2MuYAAABItm1Z+vfvL40bNzblK9oKcfDgwZIiRQpp1aqVqU3v1KmTKYvJmjWrZMyYUXr16mWC8sTuyKIIzAEAAJBs/fnnnyYIP3funOTIkUNq1KhhWiHqz2rs2LESHBxsLiyknV0aNGggH3/8sU/GEuRwOBwSYC5ev+PvIQB+lyZVCn8PAfC7LA/39PcQAL+7vvMjsZMthy/5/DmqFM0kSRE15gAAAIANUMoCAAAAywTZrMbcTsiYAwAAADZAxhwAAACWIWHuGYE5AAAArENk7hGlLAAAAIANkDEHAACAZYJImXtExhwAAACwATLmAAAAsAztEj0jYw4AAADYABlzAAAAWIaEuWdkzAEAAAAbIGMOAAAA65Ayt3/GfP369dK2bVsJDw+XEydOmHUzZ86UDRs2+HtoAAAAQPIIzL/55htp0KCBhIaGys6dO+XmzZtm/aVLl2TEiBH+Hh4AAAASsY+5r/+XVNkiMB8+fLhMmjRJJk+eLKlSpXKtr169uuzYscOvYwMAAACSTY35gQMHpGbNmrHWZ8qUSS5evOiXMQEAACDx0cfc5hnzXLlyyaFDh2Kt1/ryIkWK+GVMAAAAQLILzDt37ix9+vSRLVu2SFBQkJw8eVJmz54t/fv3l+7du/t7eAAAAEgkQRYsSZUtSlkGDBggUVFRUq9ePbl27ZopawkJCTGBea9evfw9PAAAAMDnghwOh0Ns4tatW6ak5cqVK1K6dGlJnz59gh7n4vU7iT42IKlJkyqFv4cA+F2Wh3v6ewiA313f+ZHYye4//vH5c5TPn0GSIluUssyaNctkylOnTm0C8kceeSTBQTkAAACQFNkiMO/bt6+EhYVJ69at5bvvvpM7d8h4AwAABCL6mNs8MD916pTMnTvXTPx89tlnJXfu3NKjRw/ZuHGjv4cGAAAAJJ/APGXKlPLUU0+ZTixnzpyRsWPHytGjR6VOnTpStGhRfw8PAAAAidjH3NdLUmWLrizRpU2bVho0aCAXLlyQY8eOyb59+/w9JAAAACB5ZMyVTv7UjHmjRo0kb968Mm7cOGnWrJn8+uuv/h4aAAAAEgl9zG2eMW/ZsqUsWbLEZMu1xnzQoEESHh7u72EBAAAAySswT5EihXz55ZemhEV/BgAAQIBKyint5BCYawkLAAAAkJz5LTAfP368dOnSRdKkSWN+vpvevXtbNi4AAAD4TlLuM+5rQQ6HwyF+ULhwYdm2bZtky5bN/OyJ9jb//fffvXrsi9e5QJE/6IWhJk+aKMuWLpbz5/6W7DnC5Mmnm0rHzt3M3xHWSpOKsjB/mTtntsyYNlX+/vusFC9RUga8MUjKlivn72ElS1ke7unvIQSc6g8Vlb7t6stDpQtI7hyZ5Nm+/5bFa/a47g/LmkGG92ki9cNLSab0obJhxyHpN+orOXz8rGubnNkyyIiXm0ndqiUlQ7oQ+e3oGRk1dbksXLnLT68qsF3f+ZHYya8nrvr8OcrkTSdJkd8y5keOHInzZyRdM6dNkflfzZW3h0VIkaLFZN/eX2T44Dclffr08lzr5/09PMASy77/TsaMipC3Bg+VsmXLy+yZM6R7106yaMkyk4gAkrp0oSHy828n5PNFm2TeB11i3f/l2C4SefuO/OvlT+Xy1RvSu21d+W5SL6nYfLhcu3HLbDPlnXaSOUOo2ebvi1fkuYaVZdZ7HaV6m1Gy+8CffnhVsBK5Opu3Sxw2bJhplxjT9evXzX1IGvbs3iU1a9eVGjVrSZ68eaXeYw3kkfDqsveXn/09NMAyM2dMk+bPPCtNm7WQosWKmQBdS/YWzv/G30MDEsUP/9krQz9eIt+u/l+W3KlYgTCpUq6w9H53rmzfe1wOHjsjvUfMkzQhqeTZhpVc21UtX0Q+nrtWtv16TI6eOCfvTVkuF/+5LhVL57f41QD2YovAfOjQoXLlypVY6zVY1/uQNJQrX0G2bdksx48dNbd/O7Bfdu/cIeHVH/X30ABLRN66Jfv2/ipVw6u51gUHB0vVqtVkz+6dfh0bYIWQ1P89EX/j1m3XOq2YvXXrtlSr8L8reW/e/bs883glyZIxrSl1/FeDSpImJKWs23bQL+OGtehjbvOuLPqhjasGeffu3ZI1a1a/jAnea9exs1y9elWebfqkBKdIIVF37ki3nn3kiScb+3togCUuXLxg5lrELFnR20eOeDdXBkiKDhw9LcdPnZd3ej0tPYd/IVev35LebetIvlxZJFf2TK7t2r72mcx8r6OcXDtKIiPvmBKX5/pNlt//+Nuv4weSdWCeJUsWE5DrUrx4cbfgXP/jpln0bt263fUxbt68aRa3dVEpJSQkxGfjRtx+/GGZLPtuiQyLGG1qzDVjPnZ0hOT4/0mgAIDAdvt2lLR8ZbJ8MriNnFo3Wm7fviOrthyQZRt+dasrHtzjKVNj3rDreDl38ao0rl1OZo3qKPU7jpNfD53050uAFZJySjuQA/Nx48aZbHnHjh1NyUqmTP87mk6dOrUUKlTonlcAjYiIiFXu8vobg2TAW4N9Nm7EbcLYMdKuw4vy+BONzO1iDxSX06dOyozPJhOYI1nIkjmLuUjauXPn3Nbr7ezZs/ttXICVdu77Q6q2HCkZ06eR1KlSyt8Xrsi6z/ubmnNVOF926d6yljzUYrjs+/20WaeTSbXbS9fnapr6dCC58mtg3r59e/OvtkusVq2apEqVyuvHGDhwoPTr189t3fUoW1ToJDs3blw39bTR6e2oqCi/jQmwUqrUqaVU6TKyZfMmqVuvvlmn+/+WLZukZau2/h4eYKnLV26Yf4sWyGFaK+qEUZU2TWrzb1SMbs137jgkmHYdyQJ9zD3zWwR7+fJlyZgxo/m5YsWKpgOLLnFxbhcXLVmJWbYSRR9zv3i0Zh2ZNuVTyZkr9/+XsuyTL2bNkMZNmvt7aIBlnm/fQQa98bqUKfOgPFi2nMyaOcN8tzVtxucAgSFdaGopmj+H63ahvNmkXPG8cuHyNfnj9AVpXr+inL1wRf44fV4efCCPjHn1GdPnfOXm/a469EPHz8hHb7WSgR8skHOXrsrTdcpJvaolpHmfSX58ZUAyvsCQnu49deqUhIWFmaxqXJM/nZNCtd7cG1xgyD904uenE8fL2tU/yoXz580FhrSspVPX7pIq1X8zJLAOFxjyny9mz3JdYKhEyVLy+htvSbly5f09rGSJCwwlvkcrPSA/TOkTa/3MbzdLl8Gz5KVWtcwFiMKyZZDTf1+W2Uu2SMS/l5ne5k6aRR/eu4mEVygi6dOGyOE/zsq4z1fKF0u3Wvxqkge7XWDowOnYLbITW4lcaSUp8ltgvnbtWqlevbqkTJnS/Hw3tWrV8uqxCcwBAnNAEZgDBOZJid9KWaIH294G3gAAAEiaqDC3+QWGli1bJhs2bHDdnjhxolSoUEFat24tFy5c8OvYAAAAgGQTmL/66qtmMqj6+eefTZeVRo0ayZEjR2J1XAEAAEASxqU/PbJFX0ENwEuXLm1+/uabb6Rx48YyYsQI2bFjhwnQAQAAgEBni4y5Xkzo2rX/TgT48ccf5fHHHzc/Z82a1ZVJBwAAQGD0Mff1/5IqW2TMa9SoYUpWtEvLTz/9JPPmzTPrf/vtN8mXL5+/hwcAAAAkj4z5Rx99ZNomfv311/LJJ59I3rx5zfrvv/9ennjiCX8PDwAAAIlEL13j6yWp8lsfc1+ijzlAH3NA0cccsF8f80Nn4r7Se2IqFhYqSZEtSlmUXt1z4cKFsm/fPnO7TJky8vTTT5srhAIAACAwJOGEdvIIzA8dOmS6r5w4cUJKlChh1kVEREj+/Pll6dKlUrRoUX8PEQAAAAj8GvPevXub4PuPP/4wLRJ1OX78uBQuXNjcBwAAgABBH3N7B+Zr166VUaNGmfaITtmyZZORI0ea+wAAAABf0CqNhx9+WDJkyCBhYWHStGlTOXDggNs2tWvXlqCgILelW7dugRmYh4SEyD///BNr/ZUrV0yPcwAAAAQGu/UxX7t2rfTo0UM2b94sK1askMjISHNNnatXr7pt17lzZzl16pRr0aRyQNaYP/XUU9KlSxeZOnWqPPLII2bdli1bzJGITgAFAAAAfGHZsmVut6dPn24y59u3b5eaNWu61qdNm1Zy5colvmSLjPn48eOlWLFiUq1aNUmTJo1Z9GJDuu7DDz/09/AAAACQhPqY37x501w9Pvqi6+Lj0qVL5t/oJdZq9uzZkj17dnnwwQdl4MCBrqvWB0zGPCoqSkaPHi3ffvut3Lp1y9T0tG/f3tTtlCpVygTmAAAAgLd140OHDnVbN3jwYBkyZMg9Y9OXX37ZJIg1AHdq3bq1FCxYUPLkySN79uyR119/3dShz58/XwLmAkPvvPOOeYPq168voaGhsnz5cmnVqpV89tln9/W4XGAI4AJDgOICQ4D9LjB09O8bPn+O3BmCYmXIdU6jLnfTvXt3c+X5DRs2SL58+Txut2rVKqlXr55p+Z2Ybb39Wsry+eefy8cff2wCcr240OLFi81pAj1aAQAAABJCA/CMGTO6LfcKynv27ClLliyR1atX3zUoV1WqVDH/amCemPwamGuvcr2wkJNmzrWM5eTJk/4cFgAAAJJJH3OHw2GC8gULFphMuF5H51527dpl/s2dO7cETI357du3zUTP6FKlSmXa1AAAAAC+pq0S58yZI4sWLTK9zE+fPm3WZ8qUyZRaHz582NyvyWS9zo7WmPft29d0bClXrlzg1JgHBwdLw4YN3U4taDlL3bp1JV26dK513hbWU2MOUGMOKGrMAfvVmB87F7/uKPejYLa7l61Ep9UacZk2bZq88MIL5sr0bdu2lV9++cX0Ns+fP780a9ZM3nrrLVMiEzAZc+3AEpO+cAAAAMAK98pRayBu1ZXo/RqY65EIAAAAkg8PCWr4e/InAAAAABtkzAEAAJC8kDD3jIw5AAAAYANkzAEAAGAZasw9IzAHAACAhYjMPaGUBQAAALABMuYAAACwDKUsnpExBwAAAGyAjDkAAAAsQ8LcMzLmAAAAgA2QMQcAAIBlqDH3jIw5AAAAYANkzAEAAGCZIKrMPSJjDgAAANgAGXMAAABYh4S5R2TMAQAAABsgYw4AAADLkDD3jIw5AAAAYANkzAEAAGAZ+ph7RsYcAAAAsAEy5gAAALAMfcw9I2MOAAAA2AAZcwAAAFiHhLlHZMwBAAAAGyBjDgAAAMuQMPeMjDkAAABgA2TMAQAAYBn6mHtGxhwAAACwATLmAAAAsAx9zD0jYw4AAADYABlzAAAAWIYac8/ImAMAAAA2QGAOAAAA2ACBOQAAAGAD1JgDAADAMtSYe0bGHAAAALABMuYAAACwDH3MPSNjDgAAANgAGXMAAABYhhpzz8iYAwAAADZAxhwAAACWIWHuGRlzAAAAwAbImAMAAMA6pMw9ImMOAAAA2AAZcwAAAFiGPuaekTEHAAAAbICMOQAAACxDH3PPyJgDAAAANkDGHAAAAJYhYe4ZGXMAAADABsiYAwAAwDqkzD0iYw4AAIBkb+LEiVKoUCFJkyaNVKlSRX766SfLx0BgDgAAAEv7mPv6f96aN2+e9OvXTwYPHiw7duyQ8uXLS4MGDeTMmTNiJQJzAAAAJGsffPCBdO7cWTp06CClS5eWSZMmSdq0aeWzzz6zdBwE5gAAALC0j7mvF2/cunVLtm/fLvXr13etCw4ONrc3bdokVmLyJwAAAALKzZs3zRJdSEiIWWL6+++/5c6dO5IzZ0639Xp7//79YqWADMwzh6bw9xCSNf0gREREyMCBA+P8AADJAZ8De7i+8yN/DyFZ43OAuKSxIPocMjxChg4d6rZO68eHDBkidhbkcDgc/h4EAsvly5clU6ZMcunSJcmYMaO/hwP4BZ8DgM8BkkbG/NatW6ae/Ouvv5amTZu61rdv314uXrwoixYtEqtQYw4AAICAEhISYg4Goy+eztqkTp1aKlWqJCtXrnSti4qKMrfDw8MtHHWAlrIAAAAA8aWtEjVDXrlyZXnkkUdk3LhxcvXqVdOlxUoE5gAAAEjWnnvuOTl79qy8/fbbcvr0aalQoYIsW7Ys1oRQXyMwR6LTU0U6wYKJPkjO+BwAfA6QtPTs2dMs/sTkTwAAAMAGmPwJAAAA2ACBOQAAAGADBObwu0KFCpnZzwDiZ82aNRIUFGT66wJJdf/kux+IjcA8wL3wwgvmC3LkyJFu6xcuXGjWW2n69OmSOXPmWOu3bt0qXbp0sXQsgJWfj6NHj5rH27VrV6I9JpBY+78u2se5WLFiMmzYMLl9+/Z9PW61atXk1KlT5sJCiu9+IP4IzJOBNGnSyHvvvScXLlwQO8qRI4e54haQ3D8fevU5wEpPPPGECaIPHjwor7zyirlc+ejRo+/rMTXIz5Ur1z0PbvnuB2IjME8G6tevb74kIyIiPG6zYcMGefTRRyU0NFTy588vvXv3No31nfSL+8knnzT3Fy5cWObMmRPrNOQHH3wgZcuWlXTp0pnHeOmll+TKlSuuU5vapF8vy+zM0Oh/AFT0x2ndurXpJRpdZGSkZM+eXT7//HPX1bj0teg4dDzly5c3l9EF/PX50P1Zs+zRaYZQM4VK91VVsWJFs23t2rVdGUu9/PO7774refLkkRIlSpj1M2fONBe5yJAhgxmbfi7OnDnjk9eP5E3bGOo+VrBgQenevbv5PHz77bfmQLVdu3aSJUsWEzw3bNjQBO9Ox44dk8aNG5v79Tu/TJky8t1338UqZeG7H/AOgXkykCJFChkxYoRMmDBB/vzzz1j3Hz582GRNWrRoIXv27JF58+aZQCR6L0/9gj558qT5kv3mm2/k3//+d6xAITg4WMaPHy+//vqrzJgxQ1atWiWvvfaa69SmfgHrJXE1yNelf//+scbSpk0bWbx4sSugV8uXL5dr165Js2bNzG39YtYv6kmTJpnn6tu3r7Rt21bWrl2bqO8bkofE+Hzcy08//WT+/fHHH82+P3/+fNd9esnnAwcOyIoVK2TJkiWugOSdd96R3bt3m4BfS2E0iAd8TQNePXOj+9u2bdtMkL5p0ybRzsqNGjUy+6bq0aOH3Lx5U9atWyc///yzOeuUPn36WI/Hdz/gJe1jjsDVvn17R5MmTczPVatWdXTs2NH8vGDBAu1fb37u1KmTo0uXLm6/t379ekdwcLDj+vXrjn379pltt27d6rr/4MGDZt3YsWM9PvdXX33lyJYtm+v2tGnTHJkyZYq1XcGCBV2PExkZ6ciePbvj888/d93fqlUrx3PPPWd+vnHjhiNt2rSOjRs3uj2GvgbdDrD686F0W/2d6HRf131eHTlyxGyzc+fOWM+fM2dOx82bN+86Tv3s6e//888/5vbq1avN7QsXLtznO4DkLPr+HxUV5VixYoUjJCTE0bRpU7N//ec//3Ft+/fffztCQ0MdX375pbldtmxZx5AhQ+J83Jj7J9/9QPxx5c9kRDMadevWjZWt0KycZgJnz57tWqexhp42PHLkiPz222+SMmVKeeihh1z36yQhPYUZnWYDNaOxf/9+uXz5splAdOPGDZPxiG8doT7Ps88+a8by/PPPm3KBRYsWydy5c839hw4dMo/32GOPuf2eZni0TACw+vNRqlSp+3peLf/Smtzotm/fbk7363NrSYE+lzp+/LiULl36vp4PiE7P0mimWzPhup9pSUnz5s3N+ipVqri2y5Ytmym12rdvn7mt5Vxa+vLDDz+Y8hc9o1SuXLkEj4PvfuC/CMyTkZo1a0qDBg1k4MCBbqfF9dRh165dzRdtTAUKFDCB+b3oqfannnrKfFFrvWzWrFnN6f5OnTqZL05vJvjoKc1atWqZUhk9va+nVrWUwDlWtXTpUsmbN6/b73HJZ/jj86G0bjbmRZSdp/zvRetzo9OARMehiwYpOkFOA3K9zeRQJLY6derIJ598Yg4OdZ6DBshavnIvL774otkn9btYg3NNyrz//vvSq1evBI+F736AwDzZ0bZwFSpUcE0yU5oJ37t3r8mCx0W31ez3zp07pVKlSq7sRfQuFprh02yLfjFrrbn68ssv3R5Hv/jv3LlzzzFqTaJOsNNa3u+//17+9a9/SapUqcx9mi3UL2ENVPQLHPD350Np8Ky1s046SU6ze07OjHh89n8943Tu3DkzFv0cKK31BXxBDwxj7tt6Fki/87ds2WK+j5XukzoXIvoZG90/u3XrZhY9oJ08eXKcgTnf/UD8EZgnM3raXLMSOknT6fXXX5eqVauayWyaBdEvag1ENGPx0UcfScmSJc2pSu03q5kV/aLUtlqazXC2w9Ivds0Q6gQ6nan/n//8x0zQiU5n4GvWQye76Wx6zaJ7yqTr6VT9fc3Wr1692rVeu1RoqYFO+tEDgRo1apjZ/vp8Ormoffv2PnvvEPgS8vlQWgKjP4eHh5sARH/HGVCosLAw83lZtmyZ5MuXz7RodPZ4jisLr4GMfpY04Pnll1/MRFDAKg888IA0adJEOnfuLJ9++qn53h0wYIDJVOt69fLLL5tOLcWLFzdJGv2e9lTWxXc/4AUv6tGRxCf3OOlEtNSpU7smt6mffvrJ8dhjjznSp0/vSJcunaNcuXKOd99913X/yZMnHQ0bNjQTg3TCzpw5cxxhYWGOSZMmubb54IMPHLlz5zYThBo0aGAm8cScoNatWzczIVTXDx48ONYEIKe9e/eabfQ+nZQUnd4eN26co0SJEo5UqVI5cuTIYZ5v7dq1ifjOITlIrM/HiRMnHI8//ri574EHHnB89913bpM/1eTJkx358+c3k0Zr1arl8fmVfr4KFSpkPm/h4eGOb7/91m3yKJM/kRg87X/q/Pnzjueff97sx87v9N9++811f8+ePR1FixY1+6h+B+u2OkHU0/7Jdz8QP0H6f94E8oDStnJ6ylEnfNarV8/fwwEAAEjyCMwRL9qTXE9F6ql+raXV/uQnTpwwpxujn7IHAABAwlBjjnjR+vE33nhDfv/9d1Prp5N0tGMEQTkAAEDiIGMOAAAA2MB/+9oBAAAA8CsCcwAAAMAGCMwBAAAAGyAwBwAAAGyAwBwAAACwAQJzAMnOCy+8IE2bNnXdrl27trnEuNXWrFkjQUFBcvHiRcteq13HCQAgMAdgExpAavCnS+rUqaVYsWIybNgwuX37ts+fe/78+fLOO+/YMkgtVKiQjBs3zpLnAgD4FxcYAmAbTzzxhEybNk1u3rwp3333nfTo0cNcxGrgwIGxtr1165YJ4BND1qxZE+VxAAC4H2TMAdhGSEiI5MqVSwoWLCjdu3eX+vXry7fffutWkvHuu+9Knjx5pESJEmb9H3/8Ic8++6xkzpzZBNhNmjSRo0ePuh7zzp070q9fP3N/tmzZ5LXXXpOY11WLWcqiBwavv/665M+f34xJs/dTp041j1unTh2zTZYsWUzmXMeloqKiJCIiQgoXLiyhoaFSvnx5+frrr92eRw82ihcvbu7Xx4k+zoTQ19apUyfXc+p78uGHH8a57dChQyVHjhySMWNG6datmzmwcYrP2AEAvkfGHIBtaZB47tw51+2VK1eawHLFihXmdmRkpDRo0EDCw8Nl/fr1kjJlShk+fLjJvO/Zs8dk1N9//32ZPn26fPbZZ1KqVClze8GCBVK3bl2Pz9uuXTvZtGmTjB8/3gSpR44ckb///tsE6t988420aNFCDhw4YMaiY1Qa2M6aNUsmTZokDzzwgKxbt07atm1rguFatWqZA4jmzZubswBdunSRbdu2ySuvvHJf748G1Pny5ZOvvvrKHHRs3LjRPHbu3LnNwUr09y1NmjSmDEcPBjp06GC214Oc+IwdAGARBwDYQPv27R1NmjQxP0dFRTlWrFjhCAkJcfTv3991f86cOR03b950/c7MmTMdJUqUMNs76f2hoaGO5cuXm9u5c+d2jBo1ynV/ZGSkI1++fK7nUrVq1XL06dPH/HzgwAFNp5vnj8vq1avN/RcuXHCtu3HjhiNt2rSOjRs3um3bqVMnR6tWrczPAwcOdJQuXdrt/tdffz3WY8VUsGBBx9ixYx3x1aNHD0eLFi1ct/V9y5o1q+Pq1auudZ988okjffr0jjt37sRr7HG9ZgBA4iNjDsA2lixZIunTpzeZcM0Gt27dWoYMGeK6v2zZsm515bt375ZDhw5JhgwZ3B7nxo0bcvjwYbl06ZKcOnVKqlSp4rpPs+qVK1eOVc7itGvXLkmRIoVXmWIdw7Vr1+Sxxx5zW6/lIhUrVjQ/79u3z20cSjP992vixInmbMDx48fl+vXr5jkrVKjgto1m/dOmTev2vFeuXDFZfP33XmMHAFiDwByAbWjd9SeffGKCb60j1yA6unTp0rnd1qCyUqVKMnv27FiPpWUYCeEsTfGGjkMtXbpU8ubN63af1qj7yty5c6V///6mPEeDbT1AGT16tGzZssX2YwcAxEZgDsA2NPDWiZbx9dBDD8m8efMkLCzM1HvHReutNVCtWbOmua3tF7dv325+Ny6aldds/dq1a83k05icGXudeOlUunRpE8Rq1tpTpl3r250TWZ02b94s9+M///mPVKtWTV566SXXOj1TEJOeWdBsuvOgQ59Xz0xozbxOmL3X2AEA1qArC4Akq02bNpI9e3bTiUUnf+okTZ3g2Lt3b/nzzz/NNn369JGRI0fKwoULZf/+/SaIvVsPcu0b3r59e+nYsaP5Hedjfvnll+Z+7Rij3Vi07Obs2bMm46yZas1c9+3bV2bMmGGC4x07dsiECRPMbaWdUA4ePCivvvqqmTg6Z84cMyk1Pk6cOGFKbKIvFy5cMBM1dRLp8uXL5bfffpNBgwbJ1q1bY/2+lqVo95a9e/eazjCDBw+Wnj17SnBwcLzGDgCwBoE5gCRL66a1g0iBAgVMxxPNSmsAqjXmzgy6dj55/vnnTbDtLPdo1qzZXR9Xy2meeeYZE8SXLFlSOnfuLFevXjX3abmHth4cMGCA5MyZ0wS4Si9QpIGxdjjRcWhnGC0P0RaESseoHV002Neab+2AMmLEiHi9zjFjxph67+iLPnbXrl3N637uuedM/bp2sImePXeqV6+eCeL1rIFu+/TTT7vV7t9r7AAAawTpDFCLngsAAACAB2TMAQAAABsgMAcAAABsgMAcAAAAsAECcwAAAMAGCMwBAAAAGyAwBwAAAGyAwBwAAACwAQJzAAAAwAYIzAEAAAAbIDAHAAAAbIDAHAAAALABAnMAAABA/O//AOLKCHwis8JDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 20 Features for 'Positive' Sentiment (Logistic Regression) ---\n",
      "  great: 2.2830\n",
      "  good: 2.1682\n",
      "  easy: 1.4171\n",
      "  best: 1.3164\n",
      "  love: 1.2562\n",
      "  like: 1.1210\n",
      "  nice: 0.9510\n",
      "  helpful: 0.8492\n",
      "  free: 0.8354\n",
      "  thanks: 0.8177\n",
      "  great app: 0.7378\n",
      "  perfect: 0.7276\n",
      "  amazing: 0.6839\n",
      "  far: 0.6630\n",
      "  better: 0.6525\n",
      "  really: 0.6361\n",
      "  stock: 0.6292\n",
      "  kind: 0.6194\n",
      "  trust: 0.6112\n",
      "  support: 0.6095\n",
      "\n",
      "--- Top 20 Features for 'Negative' Sentiment (Logistic Regression) ---\n",
      "  bad: 1.7986\n",
      "  scam: 1.2488\n",
      "  annoying: 1.1302\n",
      "  refund: 1.1112\n",
      "  waste: 1.0004\n",
      "  terrible: 0.9961\n",
      "  return: 0.9943\n",
      "  problem: 0.9312\n",
      "  difficult: 0.9020\n",
      "  open: 0.8978\n",
      "  worst: 0.8937\n",
      "  wrong: 0.7329\n",
      "  waste time: 0.7236\n",
      "  fake: 0.6765\n",
      "  blocked: 0.6709\n",
      "  poor: 0.6672\n",
      "  negative: 0.6456\n",
      "  frustrating: 0.6448\n",
      "  aliexpress: 0.6303\n",
      "  rejected: 0.6263\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Detailed Evaluation of Best Model\n",
    "print(f\"\\n--- Detailed Evaluation for {best_model_name} ---\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\n",
    "plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance (Example for Logistic Regression)\n",
    "if \"Logistic Regression\" in best_model_name:\n",
    "    # Get the TfidfVectorizer and the classifier from the pipeline\n",
    "    tfidf = best_model.named_steps['tfidf']\n",
    "    classifier = best_model.named_steps['classifier']\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "    # Get coefficients for the 'Positive' class (class 2, adjust index if needed)\n",
    "    # Coefficients shape: (n_classes, n_features)\n",
    "    coef = classifier.coef_\n",
    "\n",
    "    # --- Analyze features for 'Positive' sentiment ---\n",
    "    # Find the index for 'Positive' in classifier.classes_\n",
    "    pos_class_idx = np.where(classifier.classes_ == 'Positive')[0][0]\n",
    "    pos_coef = coef[pos_class_idx]\n",
    "\n",
    "    # Get top 20 features for Positive\n",
    "    top_positive_indices = np.argsort(pos_coef)[::-1][:20]\n",
    "    top_positive_features = [(feature_names[i], pos_coef[i]) for i in top_positive_indices]\n",
    "    print(f\"\\n--- Top 20 Features for 'Positive' Sentiment ({best_model_name}) ---\")\n",
    "    for feature, coef_val in top_positive_features:\n",
    "        print(f\"  {feature}: {coef_val:.4f}\")\n",
    "\n",
    "    # --- Analyze features for 'Negative' sentiment ---\n",
    "    neg_class_idx = np.where(classifier.classes_ == 'Negative')[0][0]\n",
    "    neg_coef = coef[neg_class_idx]\n",
    "    top_negative_indices = np.argsort(neg_coef)[::-1][:20] # High positive coef for Negative class means strong indicator\n",
    "    top_negative_features = [(feature_names[i], neg_coef[i]) for i in top_negative_indices]\n",
    "    print(f\"\\n--- Top 20 Features for 'Negative' Sentiment ({best_model_name}) ---\")\n",
    "    for feature, coef_val in top_negative_features:\n",
    "        print(f\"  {feature}: {coef_val:.4f}\")\n",
    "\n",
    "# Note: Feature importance for Random Forest would use `classifier.feature_importances_`\n",
    "# but accessing features from the pipeline's TfidfVectorizer is slightly different.\n",
    "# It's often easier to inspect coefficients for linear models like Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb8eb95-2374-429d-a801-2a25baa30e47",
   "metadata": {},
   "source": [
    "# 1. Feature Importance Analysis (Logistic Regression Coefficients) \n",
    "\n",
    "This analysis reveals the words and phrases the model finds most indicative of Positive or Negative sentiment. \n",
    "\n",
    "    Top Features for 'Positive' Sentiment: \n",
    "        The model strongly associates words like great, good, easy, best, love, like, nice with positive sentiment. Phrases like great app also rank highly. These are classic positive sentiment indicators in reviews.\n",
    "        Insight: The model has learned intuitive and expected associations for positive feedback.\n",
    "         \n",
    "\n",
    "    Top Features for 'Negative' Sentiment: \n",
    "        The model identifies words like bad, scam, annoying, refund, waste, terrible, problem, difficult as strong indicators of negative sentiment. The phrase waste time also appears.\n",
    "        Insight: Similarly, the model has learned clear indicators for negative feedback, including terms related to problems and dissatisfaction.\n",
    "         \n",
    "     \n",
    "\n",
    "2. Classification Report Interpretation \n",
    "\n",
    "The classification report gives a detailed breakdown of performance for each sentiment class: \n",
    "\n",
    "    Positive Class:\n",
    "        Precision (0.76): When the model predicts 'Positive', it's correct 76% of the time.\n",
    "        Recall (0.96): It successfully identifies 96% of all actual 'Positive' reviews.\n",
    "        F1-Score (0.85): This high F1-score indicates very strong performance for the 'Positive' class. The model is excellent at finding positive reviews and is fairly accurate when it predicts positive.\n",
    "         \n",
    "    Negative Class:\n",
    "        Precision (0.75): When the model predicts 'Negative', it's correct 75% of the time.\n",
    "        Recall (0.36): Crucially, it only identifies 36% of actual 'Negative' reviews. This means it misses many negative reviews, often predicting them as 'Positive'.\n",
    "        F1-Score (0.48): This moderate F1-score reflects the imbalance between precision and recall. The low recall is the main weakness here.\n",
    "         \n",
    "    Neutral Class:\n",
    "        Precision, Recall, F1-Score (0.00): This is the most concerning result. The model completely fails to correctly predict any 'Neutral' reviews. All 10 actual 'Neutral' reviews in the test set were misclassified (likely as 'Positive' or 'Negative').\n",
    "        Insight: The extreme class imbalance (only 10 'Neutral' vs. 206 'Positive' and 84 'Negative' in the test set) has caused the model to essentially ignore this class during training.\n",
    "         \n",
    "    Overall Accuracy (0.76): This matches the score from the previous step. However, as suspected, this high accuracy is heavily influenced by the model's strong performance on the dominant 'Positive' class.\n",
    "# 3. Confusion Matrix Interpretation\n",
    "    Negative Class: Out of 84 actual 'Negative' reviews, 30 were correctly predicted as 'Negative', but a significant 54 were incorrectly predicted as 'Positive'. This confirms the low recall (30/84 â 0.36).\n",
    "    Neutral Class: All 10 actual 'Neutral' reviews were misclassified (2 as 'Negative', 8 as 'Positive'). This confirms the 0.00 scores in the classification report.\n",
    "    Positive Class: Out of 206 actual 'Positive' reviews, a very high 198 were correctly predicted as 'Positive', with only 8 misclassified (mostly as 'Negative'). This confirms the high recall (198/206 â 0.96).\n",
    "    Predictions: The model made very few 'Negative' (40) or 'Neutral' (0) predictions, heavily favoring 'Positive' predictions (260). This directly reflects the class imbalance in the training data.\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4085dc3-a7cd-4c12-831e-935afbf04f7b",
   "metadata": {},
   "source": [
    "# Conclusion & Recommendations: \n",
    "\n",
    "Your Logistic Regression model, while achieving a decent overall accuracy of 76%, exhibits clear weaknesses directly related to the class imbalance in your dataset: \n",
    "\n",
    "    Strength: It performs exceptionally well for the majority class, 'Positive' sentiment (High Precision and Recall).\n",
    "    Weakness 1: It performs poorly for the minority class, 'Negative' sentiment, primarily due to very low recall (it misses many negative reviews).\n",
    "    Weakness 2: It completely fails to identify the smallest class, 'Neutral' sentiment.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd02f4f-fd19-469a-994d-6badef4b43f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pipelines defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Models\n",
    "# Define the models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]),\n",
    "    \"Naive Bayes\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ]),\n",
    "    # --- ADD THE NEW BALANCED MODEL HERE ---\n",
    "    \"Logistic Regression Balanced\": Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('classifier', LogisticRegression(random_state=42, class_weight='balanced')) # CHANGED HERE\n",
    "    ])\n",
    "    # --- END OF ADDITION ---\n",
    "}\n",
    "\n",
    "print(\"Model pipelines defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4aee8-cd86-4561-a528-66b343e1f15c",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 7 - Comparing Models with Balanced Class Weights \n",
    "\n",
    "As identified in the previous detailed evaluation, the standard Logistic Regression model struggled significantly with the minority classes, particularly 'Neutral', due to the severe class imbalance in the dataset (Positive >> Negative >> Neutral). To address this, we implemented a common and effective technique: adjusting class weights during training. \n",
    "\n",
    "Methodology: \n",
    "\n",
    "We added a new model variant to our comparison: \n",
    "\n",
    "    \"Logistic Regression Balanced\": This pipeline is identical to the standard \"Logistic Regression\" model, with one crucial difference:\n",
    "        The LogisticRegression classifier was initialized with the parameter class_weight='balanced'.\n",
    "        This setting instructs Scikit-learn to automatically adjust the penalty (cost of misclassification) for each class inversely proportional to its frequency in the training data. In essence, the model is told to pay more attention to correctly classifying the rare 'Negative' and 'Neutral' reviews, as misclassifying them becomes more \"expensive\" during the training process.\n",
    "         \n",
    "     \n",
    "\n",
    "Purpose: \n",
    "\n",
    "The goal of this step was to re-evaluate our models, specifically to see if applying class_weight='balanced' to the Logistic Regression algorithm could mitigate the negative impact of class imbalance and lead to improved performance (especially recall) for the minority sentiment classes, even if it potentially slightly reduced overall accuracy. \n",
    "\n",
    "Expected Outcomes: \n",
    "\n",
    "By comparing the performance of the standard Logistic Regression against the balanced version (and the other models like Random Forest and Naive Bayes), we aim to determine: \n",
    "\n",
    "    Does class_weight='balanced' improve the model's ability to predict 'Negative' and 'Neutral' sentiments?\n",
    "    How does this adjustment affect the overall accuracy?\n",
    "    Does the balanced Logistic Regression become the new best-performing model based on our chosen metric (accuracy), or does it offer a better trade-off between accuracy and recall for minority classes?\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf0cc0b3-5e2e-4eab-a526-7f2df258159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression ---\n",
      "Logistic Regression Accuracy: 0.7600\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Random Forest Accuracy: 0.7267\n",
      "\n",
      "--- Training Naive Bayes ---\n",
      "Naive Bayes Accuracy: 0.7033\n",
      "\n",
      "--- Training Logistic Regression Balanced ---\n",
      "Logistic Regression Balanced Accuracy: 0.7300\n",
      "\n",
      "--- Best Model ---\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Train and Evaluate Models\n",
    "model_performance = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    # Fit the model (this includes fitting the TfidfVectorizer on X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    model_performance[name] = {\n",
    "        'model': model, # Store the trained pipeline\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "# Find the best model based on accuracy\n",
    "best_model_name = max(model_performance, key=lambda k: model_performance[k]['accuracy'])\n",
    "best_model = model_performance[best_model_name]['model']\n",
    "best_accuracy = model_performance[best_model_name]['accuracy']\n",
    "best_predictions = model_performance[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n--- Best Model ---\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
    "#print(f\"prediction: {best_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8c57a-0a5a-42c3-88df-151c5dd76e7a",
   "metadata": {},
   "source": [
    "# Modeling Phase: Step 8 - Analyzing Features for 'Neutral' Sentiment \n",
    "\n",
    "Having examined the features strongly associated with 'Positive' and 'Negative' sentiments, it's equally important to understand what drives the prediction for the often-overlooked 'Neutral' class, especially given its poor performance in our previous evaluations. \n",
    "\n",
    "This section focuses on the Logistic Regression model (whether standard or balanced, whichever was identified as best) to uncover the words and phrases the model has learned to associate with 'Neutral' sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75e9cb4-59c0-4bdc-87d7-6892be65aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Features for 'Neutral' Sentiment (Logistic Regression) ---\n",
      "\n",
      "--- Top 20 Features for 'Neutral' Sentiment (Logistic Regression) ---\n",
      "  message: 0.7737\n",
      "  alibaba: 0.7368\n",
      "  reasonable price: 0.6293\n",
      "  expense: 0.6279\n",
      "  invoice: 0.5840\n",
      "  jump: 0.5027\n",
      "  log: 0.4980\n",
      "  run: 0.4910\n",
      "  form: 0.4798\n",
      "  email: 0.4616\n",
      "  shipping: 0.4492\n",
      "  product supplier: 0.4452\n",
      "  transformed: 0.4452\n",
      "  security: 0.4410\n",
      "  measure: 0.4388\n",
      "  reasonable: 0.4378\n",
      "  ghost: 0.4372\n",
      "  waiting: 0.4368\n",
      "  prize: 0.4348\n",
      "  app went: 0.4333\n",
      "\n",
      "--- Top 20 Features that Push Prediction AWAY from 'Neutral' (Logistic Regression) ---\n",
      "  great: -0.3680\n",
      "  make: -0.3607\n",
      "  use: -0.3523\n",
      "  good: -0.3425\n",
      "  really: -0.3368\n",
      "  like: -0.3279\n",
      "  customer: -0.3145\n",
      "  star: -0.2897\n",
      "  review: -0.2864\n",
      "  return: -0.2857\n",
      "  problem: -0.2715\n",
      "  item: -0.2687\n",
      "  say: -0.2551\n",
      "  work: -0.2532\n",
      "  love: -0.2487\n",
      "  best: -0.2462\n",
      "  support: -0.2337\n",
      "  app: -0.2311\n",
      "  come: -0.2300\n",
      "  easy: -0.2273\n"
     ]
    }
   ],
   "source": [
    "# --- Cell X: Analyze Features for 'Neutral' Sentiment (Logistic Regression) ---\n",
    "\n",
    "# Ensure the best model is Logistic Regression (or the balanced version)\n",
    "if \"Logistic Regression\" in best_model_name:\n",
    "    print(f\"\\n--- Analyzing Features for 'Neutral' Sentiment ({best_model_name}) ---\")\n",
    "\n",
    "    # Get the TfidfVectorizer and the classifier from the pipeline\n",
    "    tfidf = best_model.named_steps['tfidf']\n",
    "    classifier = best_model.named_steps['classifier']\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "    # Get coefficients for the 'Neutral' class\n",
    "    # Coefficients shape: (n_classes, n_features)\n",
    "    coef = classifier.coef_\n",
    "\n",
    "    # --- Analyze features for 'Neutral' sentiment ---\n",
    "    # Find the index for 'Neutral' in classifier.classes_\n",
    "    try:\n",
    "        neutral_class_idx = np.where(classifier.classes_ == 'Neutral')[0][0]\n",
    "        neutral_coef = coef[neutral_class_idx]\n",
    "\n",
    "        # Get top 20 features for Neutral (highest positive coefficients)\n",
    "        # np.argsort sorts ascending, so [::-1] reverses to descending\n",
    "        top_neutral_indices = np.argsort(neutral_coef)[::-1][:20]\n",
    "        top_neutral_features = [(feature_names[i], neutral_coef[i]) for i in top_neutral_indices]\n",
    "\n",
    "        print(f\"\\n--- Top 20 Features for 'Neutral' Sentiment ({best_model_name}) ---\")\n",
    "        if top_neutral_features:\n",
    "            for feature, coef_val in top_neutral_features:\n",
    "                print(f\"  {feature}: {coef_val:.4f}\")\n",
    "        else:\n",
    "            print(\"  No features found with positive coefficients for 'Neutral' class.\")\n",
    "\n",
    "        # --- Optional: Also look at features the model strongly associates as NOT Neutral ---\n",
    "        # Features with the most negative coefficients for the Neutral class\n",
    "        # These are words that strongly push the prediction AWAY from Neutral\n",
    "        bottom_neutral_indices = np.argsort(neutral_coef)[:20] # Get indices of smallest (most negative) coefficients\n",
    "        bottom_neutral_features = [(feature_names[i], neutral_coef[i]) for i in bottom_neutral_indices]\n",
    "        print(f\"\\n--- Top 20 Features that Push Prediction AWAY from 'Neutral' ({best_model_name}) ---\")\n",
    "        if bottom_neutral_features:\n",
    "             for feature, coef_val in bottom_neutral_features:\n",
    "                 print(f\"  {feature}: {coef_val:.4f}\")\n",
    "        else:\n",
    "             print(\"  No features found with negative coefficients for 'Neutral' class.\")\n",
    "\n",
    "\n",
    "    except IndexError:\n",
    "        # This happens if 'Neutral' is not found in classifier.classes_\n",
    "        # This shouldn't happen if your y contained 'Neutral' labels, but good to check\n",
    "        print(\"Error: 'Neutral' class not found in the classifier's trained classes.\")\n",
    "        print(f\"Trained classes were: {classifier.classes_}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while analyzing Neutral features: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n--- Feature analysis for 'Neutral' skipped ---\")\n",
    "    print(f\"Best model is not Logistic Regression (it's '{best_model_name}').\")\n",
    "    print(\"Feature coefficient analysis is easiest with linear models like Logistic Regression.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63facc-3d07-4741-a194-c6ce7c6ec26a",
   "metadata": {},
   "source": [
    "# Insights: \n",
    "\n",
    "    Transactional/Administrative Language: Words like message, invoice, email, log, form, shipping, security, measure, waiting, and product supplier suggest that reviews classified as 'Neutral' by the model often discuss logistical, procedural, or factual aspects of the transaction. These reviews might be reporting on the status of an order, asking for information, or describing a process without strong positive or negative emotion.\n",
    "    Specific App/Context: The term alibaba appearing prominently might indicate that reviews for Alibaba, or discussions about Alibaba within reviews, tend to use more neutral language or discuss more transactional topics in your dataset. The phrase app went also points to potentially factual descriptions of app behavior.\n",
    "    Value-Related Terms: reasonable price and expense (along with reasonable) relate to cost but in a more neutral, evaluative way, perhaps stating a fact (\"The price was reasonable\") rather than expressing strong satisfaction (\"It was cheap!\") or dissatisfaction (\"It was expensive!\").\n",
    "    Ambiguous or Context-Dependent Terms: Words like jump, run, ghost, and prize are more ambiguous. They might appear in 'Neutral' reviews describing specific events or situations without clear sentiment. For example, \"The app went from version 1 to 2 with a big jump in features\" or \"I was waiting for the prize draw results.\"\n",
    "        Strong Sentiment Words: This list is dominated by words strongly associated with 'Positive' (great, good, like, love, best, easy) or 'Negative' (problem, return) sentiment. The presence of these words makes it highly unlikely for the model to predict 'Neutral'.\n",
    "    Common Review Terms: Words like use, customer, star, review, item, say, work, support, app, come are frequent in reviews overall but, in the context of this model, their presence (presumably combined with other cues) pushes the prediction away from the 'Neutral' class towards 'Positive' or 'Negative'.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9378ba70-8e46-4bac-be10-db798d6352be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model (Logistic Regression) saved to 'best_sentiment_model_Logistic_Regression.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save the Best Model\n",
    "model_filename = f\"best_sentiment_model_{best_model_name.replace(' ', '_')}.pkl\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\nBest model ({best_model_name}) saved to '{model_filename}'.\")\n",
    "\n",
    "# To load the model later:\n",
    "# loaded_model = joblib.load(model_filename)\n",
    "# prediction = loaded_model.predict([\"This is a great product!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa2ac4-a474-4337-bfe9-2de5a28af2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
