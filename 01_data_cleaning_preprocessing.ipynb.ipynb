{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c00edc-f0fb-440f-9686-95f4472b18f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading required NLTK data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data download complete.\n",
      "Libraries imported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "# For basic text cleaning\n",
    "from bs4 import BeautifulSoup # For removing HTML tags\n",
    "import re # For regular expressions\n",
    "import contractions # For expanding contractions (pip install contractions)\n",
    "# For NLP tasks\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "print(\"Downloading required NLTK data...\")\n",
    "nltk.download('punkt') # Tokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') # Open Multilingual Wordnet\n",
    "print(\"NLTK data download complete.\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e66997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Text Cleaning Function\n",
    "# Initialize NLTK components\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "except LookupError:\n",
    "    print(\"NLTK resources not found. Please run nltk.download() for 'stopwords' and 'wordnet'.\")\n",
    "    raise\n",
    "\n",
    "def clean_and_preprocess_text(text):\n",
    "    # ... (the full function definition from previous instructions) ...\n",
    "     if not isinstance(text, str):\n",
    "         return \"\"\n",
    "     text = text.lower()\n",
    "     text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "     text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "     emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"\n",
    "         u\"\\U0001F300-\\U0001F5FF\"\n",
    "         u\"\\U0001F680-\\U0001F6FF\"\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "         u\"\\U00002500-\\U00002BEF\"\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         u\"\\U0001f926-\\U0001f937\"\n",
    "         u\"\\U00010000-\\U0010ffff\"\n",
    "         u\"\\u2640-\\u2642\"\n",
    "         u\"\\u2600-\\u2B55\"\n",
    "         u\"\\u200d\"\n",
    "         u\"\\u23cf\"\n",
    "         u\"\\u23e9\"\n",
    "         u\"\\u231a\"\n",
    "         u\"\\ufe0f\"\n",
    "         u\"\\u3030\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "     text = emoji_pattern.sub(r'', text)\n",
    "     text = contractions.fix(text)\n",
    "     text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "     tokens = word_tokenize(text)\n",
    "     filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "     cleaned_text = ' '.join(lemmatized_tokens)\n",
    "     return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c88818-f05c-4111-aab7-5a74fceafa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQL Server successfully.\n",
      "Data loaded into DataFrame successfully.\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   ReviewID           1500 non-null   int64         \n",
      " 1   AppName            1500 non-null   object        \n",
      " 2   PlayStoreReviewID  1500 non-null   object        \n",
      " 3   UserName           1500 non-null   object        \n",
      " 4   UserImageURL       1500 non-null   object        \n",
      " 5   ReviewText         1500 non-null   object        \n",
      " 6   Rating             1500 non-null   int64         \n",
      " 7   ThumbsUpCount      1500 non-null   int64         \n",
      " 8   AppVersion         1373 non-null   object        \n",
      " 9   ReviewDate         1500 non-null   datetime64[ns]\n",
      " 10  ReplyContent       672 non-null    object        \n",
      " 11  RepliedAt          672 non-null    datetime64[ns]\n",
      " 12  ScrapedAt          1500 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(3), object(7)\n",
      "memory usage: 152.5+ KB\n",
      "None\n",
      "\n",
      "--- First 5 Rows ---\n",
      "   ReviewID     AppName                     PlayStoreReviewID       UserName  \\\n",
      "0         1  AliExpress  2cf4e22e-e7e5-46df-acff-cd77eaf9de9d  Blaise Hytrek   \n",
      "1         2  AliExpress  da753698-5370-40b4-808b-eb0a3ce149a0   David Campos   \n",
      "2         3  AliExpress  b769d4ac-1b9b-4a3d-b399-04abc34aaeb0      Lee Davis   \n",
      "3         4  AliExpress  e849cdda-2ff9-4fac-b531-40b021d504ec      Jing Wang   \n",
      "4         5  AliExpress  d8989ff9-2a7e-406b-8dfd-faf8bd48c884   Kari Eilrich   \n",
      "\n",
      "                                        UserImageURL  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                          ReviewText  Rating  ThumbsUpCount  \\\n",
      "0  Good prices but awful shipping fees. Difficult...       2             24   \n",
      "1  Easy experience the last few years. Have done ...       5           1444   \n",
      "2  Alright. There's a LOT good deals, save for th...       5            161   \n",
      "3  extremely bad. when its affiliated store cance...       1            131   \n",
      "4  The first order of 3 items for .99Â¢ is real. H...       1            830   \n",
      "\n",
      "  AppVersion          ReviewDate ReplyContent RepliedAt  \\\n",
      "0    8.133.3 2025-07-18 03:22:39         None       NaT   \n",
      "1    8.129.3 2025-05-26 11:23:12         None       NaT   \n",
      "2    8.131.2 2025-07-04 21:14:16         None       NaT   \n",
      "3    8.131.2 2025-06-29 09:30:11         None       NaT   \n",
      "4    8.122.3 2025-03-08 03:32:58         None       NaT   \n",
      "\n",
      "                   ScrapedAt  \n",
      "0 2025-07-25 22:36:06.313333  \n",
      "1 2025-07-25 22:36:06.323333  \n",
      "2 2025-07-25 22:36:06.330000  \n",
      "3 2025-07-25 22:36:06.336666  \n",
      "4 2025-07-25 22:36:06.343333  \n",
      "\n",
      "--- DataFrame Shape ---\n",
      "(1500, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15368\\4116662737.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data from SQL Server\n",
    "# --- Database Connection Configuration (Update as needed) ---\n",
    "SERVER = 'localhost' # Replace with your server name/IP\n",
    "DATABASE = 'PlayStoreReviewsDB'\n",
    "# Use Windows Authentication (common for local development)\n",
    "CONNECTION_STRING = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;'\n",
    "# Or SQL Server Authentication (uncomment and update if needed):\n",
    "# USERNAME = 'your_username'\n",
    "# PASSWORD = 'your_password'\n",
    "# CONNECTION_STRING = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD}'\n",
    "\n",
    "def load_data_from_db():\n",
    "    \"\"\"Loads data from the AppReviews table into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(CONNECTION_STRING)\n",
    "        print(\"Connected to SQL Server successfully.\")\n",
    "        # Query to select all data from the AppReviews table\n",
    "        query = \"SELECT * FROM dbo.AppReviews\"\n",
    "        # Load data into a DataFrame\n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Data loaded into DataFrame successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "# Load the data\n",
    "df = load_data_from_db()\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- DataFrame Shape ---\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54d4b4e-1091-499b-84d5-57c08544f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Types ---\n",
      "ReviewID                      int64\n",
      "AppName                      object\n",
      "PlayStoreReviewID            object\n",
      "UserName                     object\n",
      "UserImageURL                 object\n",
      "ReviewText                   object\n",
      "Rating                        int64\n",
      "ThumbsUpCount                 int64\n",
      "AppVersion                   object\n",
      "ReviewDate           datetime64[ns]\n",
      "ReplyContent                 object\n",
      "RepliedAt            datetime64[ns]\n",
      "ScrapedAt            datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "--- Unique Apps ---\n",
      "['AliExpress' 'Alibaba' 'Jiji']\n",
      "\n",
      "--- Rating Distribution ---\n",
      "Rating\n",
      "1    536\n",
      "2    127\n",
      "3    134\n",
      "4    256\n",
      "5    447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Missing Values ---\n",
      "ReviewID               0\n",
      "AppName                0\n",
      "PlayStoreReviewID      0\n",
      "UserName               0\n",
      "UserImageURL           0\n",
      "ReviewText             0\n",
      "Rating                 0\n",
      "ThumbsUpCount          0\n",
      "AppVersion           127\n",
      "ReviewDate             0\n",
      "ReplyContent         828\n",
      "RepliedAt            828\n",
      "ScrapedAt              0\n",
      "dtype: int64\n",
      "\n",
      "--- Sample Review Texts ---\n",
      "Example ReviewText:\n",
      "Good prices but awful shipping fees. Difficult to track shipping progress on orders: no arrival estimations or delivery notifications. Products often come as incorrect or flawed. Floods inboxes with spam. Store page is inconvenient to navigate. Whatever item you're looking for will be in a compilation of things under generic names (such as \"114A\" or \"blue person\").\n",
      "\n",
      "Another Example ReviewText:\n",
      "Easy experience the last few years. Have done some shopping for tech parts you wouldn't really find in the US. I went up to buying figurines and have not had an error in my orders, all parts were always included. The deals are what brings me back, some very costly items can be up to half off if you play your cards right, just make use of the games to get coins!\n",
      "\n",
      "Number of rows where ReviewText is NaN: 0\n",
      "Number of rows where ReviewText is empty string: 0\n",
      "Number of rows where ReviewText is only whitespace: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initial Data Inspection\n",
    "print(\"--- Data Types ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n--- Unique Apps ---\")\n",
    "print(df['AppName'].unique()) # Should match the apps you scraped\n",
    "\n",
    "print(\"\\n--- Rating Distribution ---\")\n",
    "print(df['Rating'].value_counts().sort_index()) # Count of each rating (1-5)\n",
    "\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df.isnull().sum()) # Count of missing values per column\n",
    "\n",
    "print(\"\\n--- Sample Review Texts ---\")\n",
    "# Look at a few examples, especially for columns that might need cleaning\n",
    "print(\"Example ReviewText:\")\n",
    "print(df['ReviewText'].iloc[0])\n",
    "print(\"\\nAnother Example ReviewText:\")\n",
    "print(df['ReviewText'].iloc[1])\n",
    "\n",
    "# Check for potential issues like empty strings\n",
    "print(f\"\\nNumber of rows where ReviewText is NaN: {df['ReviewText'].isnull().sum()}\")\n",
    "print(f\"Number of rows where ReviewText is empty string: {(df['ReviewText'] == '').sum()}\")\n",
    "print(f\"Number of rows where ReviewText is only whitespace: {(df['ReviewText'].str.strip() == '').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a06525-f7f8-4cc4-839e-4f0f831d517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Columns ---\n",
      "['ReviewID', 'AppName', 'PlayStoreReviewID', 'UserName', 'UserImageURL', 'ReviewText', 'Rating', 'ThumbsUpCount', 'AppVersion', 'ReviewDate', 'ReplyContent', 'RepliedAt', 'ScrapedAt']\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   ReviewID           1500 non-null   int64         \n",
      " 1   AppName            1500 non-null   object        \n",
      " 2   PlayStoreReviewID  1500 non-null   object        \n",
      " 3   UserName           1500 non-null   object        \n",
      " 4   UserImageURL       1500 non-null   object        \n",
      " 5   ReviewText         1500 non-null   object        \n",
      " 6   Rating             1500 non-null   int64         \n",
      " 7   ThumbsUpCount      1500 non-null   int64         \n",
      " 8   AppVersion         1373 non-null   object        \n",
      " 9   ReviewDate         1500 non-null   datetime64[ns]\n",
      " 10  ReplyContent       672 non-null    object        \n",
      " 11  RepliedAt          672 non-null    datetime64[ns]\n",
      " 12  ScrapedAt          1500 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(3), object(7)\n",
      "memory usage: 152.5+ KB\n",
      "None\n",
      "\n",
      "--- First Few Rows (Transposed for easy column viewing) ---\n",
      "                                                                   0  \\\n",
      "ReviewID                                                           1   \n",
      "AppName                                                   AliExpress   \n",
      "PlayStoreReviewID               2cf4e22e-e7e5-46df-acff-cd77eaf9de9d   \n",
      "UserName                                               Blaise Hytrek   \n",
      "UserImageURL       https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "ReviewText         Good prices but awful shipping fees. Difficult...   \n",
      "Rating                                                             2   \n",
      "ThumbsUpCount                                                     24   \n",
      "AppVersion                                                   8.133.3   \n",
      "ReviewDate                                       2025-07-18 03:22:39   \n",
      "ReplyContent                                                    None   \n",
      "RepliedAt                                                        NaT   \n",
      "ScrapedAt                                 2025-07-25 22:36:06.313333   \n",
      "\n",
      "                                                                   1  \\\n",
      "ReviewID                                                           2   \n",
      "AppName                                                   AliExpress   \n",
      "PlayStoreReviewID               da753698-5370-40b4-808b-eb0a3ce149a0   \n",
      "UserName                                                David Campos   \n",
      "UserImageURL       https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "ReviewText         Easy experience the last few years. Have done ...   \n",
      "Rating                                                             5   \n",
      "ThumbsUpCount                                                   1444   \n",
      "AppVersion                                                   8.129.3   \n",
      "ReviewDate                                       2025-05-26 11:23:12   \n",
      "ReplyContent                                                    None   \n",
      "RepliedAt                                                        NaT   \n",
      "ScrapedAt                                 2025-07-25 22:36:06.323333   \n",
      "\n",
      "                                                                   2  \\\n",
      "ReviewID                                                           3   \n",
      "AppName                                                   AliExpress   \n",
      "PlayStoreReviewID               b769d4ac-1b9b-4a3d-b399-04abc34aaeb0   \n",
      "UserName                                                   Lee Davis   \n",
      "UserImageURL       https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "ReviewText         Alright. There's a LOT good deals, save for th...   \n",
      "Rating                                                             5   \n",
      "ThumbsUpCount                                                    161   \n",
      "AppVersion                                                   8.131.2   \n",
      "ReviewDate                                       2025-07-04 21:14:16   \n",
      "ReplyContent                                                    None   \n",
      "RepliedAt                                                        NaT   \n",
      "ScrapedAt                                 2025-07-25 22:36:06.330000   \n",
      "\n",
      "                                                                   3  \\\n",
      "ReviewID                                                           4   \n",
      "AppName                                                   AliExpress   \n",
      "PlayStoreReviewID               e849cdda-2ff9-4fac-b531-40b021d504ec   \n",
      "UserName                                                   Jing Wang   \n",
      "UserImageURL       https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "ReviewText         extremely bad. when its affiliated store cance...   \n",
      "Rating                                                             1   \n",
      "ThumbsUpCount                                                    131   \n",
      "AppVersion                                                   8.131.2   \n",
      "ReviewDate                                       2025-06-29 09:30:11   \n",
      "ReplyContent                                                    None   \n",
      "RepliedAt                                                        NaT   \n",
      "ScrapedAt                                 2025-07-25 22:36:06.336666   \n",
      "\n",
      "                                                                   4  \n",
      "ReviewID                                                           5  \n",
      "AppName                                                   AliExpress  \n",
      "PlayStoreReviewID               d8989ff9-2a7e-406b-8dfd-faf8bd48c884  \n",
      "UserName                                                Kari Eilrich  \n",
      "UserImageURL       https://play-lh.googleusercontent.com/a-/ALV-U...  \n",
      "ReviewText         The first order of 3 items for .99Â¢ is real. H...  \n",
      "Rating                                                             1  \n",
      "ThumbsUpCount                                                    830  \n",
      "AppVersion                                                   8.122.3  \n",
      "ReviewDate                                       2025-03-08 03:32:58  \n",
      "ReplyContent                                                    None  \n",
      "RepliedAt                                                        NaT  \n",
      "ScrapedAt                                 2025-07-25 22:36:06.343333  \n"
     ]
    }
   ],
   "source": [
    "# --- Diagnostic Cell: Check DataFrame Structure ---\n",
    "print(\"--- DataFrame Columns ---\")\n",
    "print(df.columns.tolist()) # This lists ALL column names exactly as they are\n",
    "\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "print(df.info()) # This also shows column names and data types\n",
    "\n",
    "print(\"\\n--- First Few Rows (Transposed for easy column viewing) ---\")\n",
    "print(df.head().T) # Transposing makes columns easier to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664bde19-c5fc-43e1-a1c0-23ebe6ef548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Columns ---\n",
      "['ReviewID', 'AppName', 'PlayStoreReviewID', 'UserName', 'UserImageURL', 'ReviewText', 'Rating', 'ThumbsUpCount', 'AppVersion', 'ReviewDate', 'ReplyContent', 'RepliedAt', 'ScrapedAt']\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   ReviewID           1500 non-null   int64         \n",
      " 1   AppName            1500 non-null   object        \n",
      " 2   PlayStoreReviewID  1500 non-null   object        \n",
      " 3   UserName           1500 non-null   object        \n",
      " 4   UserImageURL       1500 non-null   object        \n",
      " 5   ReviewText         1500 non-null   object        \n",
      " 6   Rating             1500 non-null   int64         \n",
      " 7   ThumbsUpCount      1500 non-null   int64         \n",
      " 8   AppVersion         1373 non-null   object        \n",
      " 9   ReviewDate         1500 non-null   datetime64[ns]\n",
      " 10  ReplyContent       672 non-null    object        \n",
      " 11  RepliedAt          672 non-null    datetime64[ns]\n",
      " 12  ScrapedAt          1500 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(3), object(7)\n",
      "memory usage: 152.5+ KB\n",
      "None\n",
      "\n",
      "--- First Few Rows ---\n",
      "   ReviewID     AppName                     PlayStoreReviewID       UserName  \\\n",
      "0         1  AliExpress  2cf4e22e-e7e5-46df-acff-cd77eaf9de9d  Blaise Hytrek   \n",
      "1         2  AliExpress  da753698-5370-40b4-808b-eb0a3ce149a0   David Campos   \n",
      "2         3  AliExpress  b769d4ac-1b9b-4a3d-b399-04abc34aaeb0      Lee Davis   \n",
      "3         4  AliExpress  e849cdda-2ff9-4fac-b531-40b021d504ec      Jing Wang   \n",
      "4         5  AliExpress  d8989ff9-2a7e-406b-8dfd-faf8bd48c884   Kari Eilrich   \n",
      "\n",
      "                                        UserImageURL  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                          ReviewText  Rating  ThumbsUpCount  \\\n",
      "0  Good prices but awful shipping fees. Difficult...       2             24   \n",
      "1  Easy experience the last few years. Have done ...       5           1444   \n",
      "2  Alright. There's a LOT good deals, save for th...       5            161   \n",
      "3  extremely bad. when its affiliated store cance...       1            131   \n",
      "4  The first order of 3 items for .99Â¢ is real. H...       1            830   \n",
      "\n",
      "  AppVersion          ReviewDate ReplyContent RepliedAt  \\\n",
      "0    8.133.3 2025-07-18 03:22:39         None       NaT   \n",
      "1    8.129.3 2025-05-26 11:23:12         None       NaT   \n",
      "2    8.131.2 2025-07-04 21:14:16         None       NaT   \n",
      "3    8.131.2 2025-06-29 09:30:11         None       NaT   \n",
      "4    8.122.3 2025-03-08 03:32:58         None       NaT   \n",
      "\n",
      "                   ScrapedAt  \n",
      "0 2025-07-25 22:36:06.313333  \n",
      "1 2025-07-25 22:36:06.323333  \n",
      "2 2025-07-25 22:36:06.330000  \n",
      "3 2025-07-25 22:36:06.336666  \n",
      "4 2025-07-25 22:36:06.343333  \n"
     ]
    }
   ],
   "source": [
    "# --- Diagnostic Cell: Check DataFrame Structure ---\n",
    "# Make sure this cell is run AFTER you load the data into 'df'\n",
    "print(\"--- DataFrame Columns ---\")\n",
    "print(df.columns.tolist()) # This lists ALL column names exactly as they are\n",
    "\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "print(df.info()) # This also shows column names and data types\n",
    "\n",
    "# Let's also check the first few rows to be absolutely sure\n",
    "print(\"\\n--- First Few Rows ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5ccb55-a717-4b96-a395-d81b1149213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diagnostic test...\n",
      "Type of 'df': <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of 'df': (1500, 13)\n",
      "SUCCESS: Column 'ReviewText' found in df.columns!\n",
      "First ReviewText sample: 'Good prices but awful shipping fees. Difficult to track shipping progress on orders: no arrival estimations or delivery notifications. Products often come as incorrect or flawed. Floods inboxes with spam. Store page is inconvenient to navigate. Whatever item you\\'re looking for will be in a compilation of things under generic names (such as \"114A\" or \"blue person\").'\n",
      "Diagnostic test finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Simple Diagnostic Test ---\n",
    "# Run this cell immediately before the cell that fails\n",
    "print(\"Running diagnostic test...\")\n",
    "print(f\"Type of 'df': {type(df)}\")\n",
    "print(f\"Shape of 'df': {df.shape}\")\n",
    "if 'ReviewText' in df.columns:\n",
    "    print(\"SUCCESS: Column 'ReviewText' found in df.columns!\")\n",
    "    print(f\"First ReviewText sample: {repr(df['ReviewText'].iloc[0])}\") # repr shows hidden characters\n",
    "else:\n",
    "    print(\"ERROR: Column 'ReviewText' NOT found in df.columns!\")\n",
    "    print(f\"Actual columns are: {df.columns.tolist()}\")\n",
    "print(\"Diagnostic test finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3717bdc-566b-4c34-a913-b1b5221ce566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (1500, 13)\n",
      "Dropped 0 rows due to missing/empty ReviewText.\n",
      "DataFrame shape after text cleaning: (1500, 13)\n",
      "\n",
      "--- Missing Values after cleaning ---\n",
      "ReviewID               0\n",
      "AppName                0\n",
      "PlayStoreReviewID      0\n",
      "UserName               0\n",
      "UserImageURL           0\n",
      "ReviewText             0\n",
      "Rating                 0\n",
      "ThumbsUpCount          0\n",
      "AppVersion           127\n",
      "ReviewDate             0\n",
      "ReplyContent         828\n",
      "RepliedAt            828\n",
      "ScrapedAt              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Handle Missing Values and Data Types\n",
    "print(f\"Original DataFrame shape: {df.shape}\")\n",
    "\n",
    "# --- Handle Missing/Empty ReviewText ---\n",
    "# Remove rows where ReviewText is null, empty, or just whitespace\n",
    "initial_rows = df.shape[0]\n",
    "df_cleaned = df[df['ReviewText'].notnull() & (df['ReviewText'].str.strip() != '')]\n",
    "rows_after_text_clean = df_cleaned.shape[0]\n",
    "print(f\"Dropped {initial_rows - rows_after_text_clean} rows due to missing/empty ReviewText.\")\n",
    "print(f\"DataFrame shape after text cleaning: {df_cleaned.shape}\")\n",
    "\n",
    "# --- Handle Data Types (if needed) ---\n",
    "# Ensure ReviewDate is datetime (it likely already is from scraping)\n",
    "# df_cleaned['ReviewDate'] = pd.to_datetime(df_cleaned['ReviewDate'])\n",
    "\n",
    "# --- Optional: Fill other missing values with placeholders (example) ---\n",
    "# df_cleaned['UserName'].fillna('Anonymous', inplace=True)\n",
    "# df_cleaned['AppVersion'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Reset index after dropping rows (good practice)\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Missing Values after cleaning ---\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Update the main DataFrame reference\n",
    "df = df_cleaned\n",
    "del df_cleaned # Free up memory reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f3f17b-5d8b-42e0-83ee-b6af4081d399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading required NLTK data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 (or wherever you have the other downloads): Download NLTK Data\n",
    "# ... (your existing nltk.download commands) ...\n",
    "print(\"Downloading required NLTK data...\")\n",
    "nltk.download('punkt')       # Tokenizer models (older)\n",
    "nltk.download('punkt_tab')   # NEW: Tokenizer models (newer, required)\n",
    "nltk.download('stopwords')   # Stopwords list\n",
    "nltk.download('wordnet')     # WordNet lexical database (for lemmatization)\n",
    "nltk.download('omw-1.4')     # Open Multilingual Wordnet (needed for wordnet)\n",
    "print(\"NLTK data download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5d1e91-54cd-47f8-abae-f998ae07d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Good prices but awful shipping fees. Difficult to track shipping progress on orders: no arrival estimations or delivery notifications. Products often come as incorrect or flawed. Floods inboxes with spam. Store page is inconvenient to navigate. Whatever item you're looking for will be in a compilation of things under generic names (such as \"114A\" or \"blue person\").\n",
      "\n",
      "Cleaned & Preprocessed Text:\n",
      "good price awful shipping fee difficult track shipping progress order arrival estimation delivery notification product often come incorrect flawed flood inboxes spam store page inconvenient navigate whatever item looking compilation thing generic name blue person\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Text Cleaning Function\n",
    "# Initialize NLTK components (do this once per session if not already done)\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "except LookupError:\n",
    "    print(\"NLTK resources not found. Please run nltk.download() for 'stopwords' and 'wordnet'.\")\n",
    "    raise\n",
    "\n",
    "def clean_and_preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a single piece of text.\n",
    "    Steps: Lowercasing, HTML removal, URL removal, emoji removal,\n",
    "          punctuation removal, contraction expansion, tokenization,\n",
    "          stopword removal, lemmatization.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "         return \"\" # Return empty string for non-string inputs\n",
    "\n",
    "    # 1. Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # 3. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 4. Remove Emojis (basic regex approach)\n",
    "    # More robust handling can use libraries like 'demoji'\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # 5. Expand Contractions (e.g., \"don't\" -> \"do not\")\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # 6. Remove punctuation and numbers (keep only letters and spaces)\n",
    "    # You might want to be more nuanced here (e.g., keep '$' for price mentions)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # 7. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 8. Remove Stopwords\n",
    "    # Consider if domain-specific words like 'app', 'buy', 'price' should be kept\n",
    "    # For now, we'll remove standard stopwords\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 9. Lemmatization (reduces words to their base/dictionary form)\n",
    "    # e.g., 'running', 'ran' -> 'run'\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # 10. Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Test the function on a sample\n",
    "sample_text = df['ReviewText'].iloc[0]\n",
    "print(\"Original Text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nCleaned & Preprocessed Text:\")\n",
    "print(clean_and_preprocess_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ffed91-0928-412a-bc5f-1091d0abe47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text cleaning and preprocessing...\n",
      "Text cleaning and preprocessing completed.\n",
      "\n",
      "--- Sample Original vs Cleaned Text ---\n",
      "Original:\n",
      "Good prices but awful shipping fees. Difficult to track shipping progress on orders: no arrival estimations or delivery notifications. Products often come as incorrect or flawed. Floods inboxes with spam. Store page is inconvenient to navigate. Whatever item you're looking for will be in a compilation of things under generic names (such as \"114A\" or \"blue person\").\n",
      "\n",
      "Cleaned:\n",
      "good price awful shipping fee difficult track shipping progress order arrival estimation delivery notification product often come incorrect flawed flood inboxes spam store page inconvenient navigate whatever item looking compilation thing generic name blue person\n",
      "\n",
      "Original Word Count: 57\n",
      "Cleaned Word Count: 35\n",
      "\n",
      "--- Another Sample ---\n",
      "Original:\n",
      "Easy experience the last few years. Have done some shopping for tech parts you wouldn't really find in the US. I went up to buying figurines and have not had an error in my orders, all parts were always included. The deals are what brings me back, some very costly items can be up to half off if you play your cards right, just make use of the games to get coins!\n",
      "\n",
      "Cleaned:\n",
      "easy experience last year done shopping tech part would really find u went buying figurine error order part always included deal brings back costly item half play card right make use game get coin\n",
      "\n",
      "Number of reviews that became empty after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Apply Text Cleaning Function\n",
    "print(\"Starting text cleaning and preprocessing...\")\n",
    "# Apply the function to the 'ReviewText' column\n",
    "# This might take a minute or two depending on your dataset size\n",
    "df['CleanedReviewText'] = df['ReviewText'].apply(clean_and_preprocess_text)\n",
    "print(\"Text cleaning and preprocessing completed.\")\n",
    "\n",
    "# --- Optional: Feature Engineering ---\n",
    "# Calculate review length (number of words in cleaned text)\n",
    "df['ReviewWordCount'] = df['CleanedReviewText'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "# --- Inspect Results ---\n",
    "print(\"\\n--- Sample Original vs Cleaned Text ---\")\n",
    "print(\"Original:\")\n",
    "print(df['ReviewText'].iloc[0])\n",
    "print(\"\\nCleaned:\")\n",
    "print(df['CleanedReviewText'].iloc[0])\n",
    "print(f\"\\nOriginal Word Count: {len(df['ReviewText'].iloc[0].split())}\")\n",
    "print(f\"Cleaned Word Count: {df['ReviewWordCount'].iloc[0]}\")\n",
    "\n",
    "print(\"\\n--- Another Sample ---\")\n",
    "print(\"Original:\")\n",
    "print(df['ReviewText'].iloc[1])\n",
    "print(\"\\nCleaned:\")\n",
    "print(df['CleanedReviewText'].iloc[1])\n",
    "\n",
    "# Check for rows where cleaning resulted in empty strings\n",
    "empty_after_cleaning = df[df['CleanedReviewText'] == '']\n",
    "print(f\"\\nNumber of reviews that became empty after cleaning: {len(empty_after_cleaning)}\")\n",
    "if len(empty_after_cleaning) > 0:\n",
    "    print(\"Dropping these rows...\")\n",
    "    df = df[df['CleanedReviewText'] != ''].reset_index(drop=True)\n",
    "    print(f\"Final DataFrame shape after dropping empty cleaned texts: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3724bde-4b52-44c5-b69e-3d64f697c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_reviews_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Cleaned Data\n",
    "output_filename = 'cleaned_reviews_data.csv'\n",
    "df.to_csv(output_filename, index=False) # Don't save the DataFrame index\n",
    "print(f\"Cleaned data saved to '{output_filename}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae1ab0-4163-41b4-9c42-89916f046706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c036b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQL Server successfully.\n",
      "Data loaded into DataFrame successfully.\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   ReviewID           1500 non-null   int64         \n",
      " 1   AppName            1500 non-null   object        \n",
      " 2   PlayStoreReviewID  1500 non-null   object        \n",
      " 3   UserName           1500 non-null   object        \n",
      " 4   UserImageURL       1500 non-null   object        \n",
      " 5   ReviewText         1500 non-null   object        \n",
      " 6   Rating             1500 non-null   int64         \n",
      " 7   ThumbsUpCount      1500 non-null   int64         \n",
      " 8   AppVersion         1373 non-null   object        \n",
      " 9   ReviewDate         1500 non-null   datetime64[ns]\n",
      " 10  ReplyContent       672 non-null    object        \n",
      " 11  RepliedAt          672 non-null    datetime64[ns]\n",
      " 12  ScrapedAt          1500 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(3), object(7)\n",
      "memory usage: 152.5+ KB\n",
      "None\n",
      "\n",
      "--- First 5 Rows ---\n",
      "   ReviewID     AppName                     PlayStoreReviewID       UserName  \\\n",
      "0         1  AliExpress  2cf4e22e-e7e5-46df-acff-cd77eaf9de9d  Blaise Hytrek   \n",
      "1         2  AliExpress  da753698-5370-40b4-808b-eb0a3ce149a0   David Campos   \n",
      "2         3  AliExpress  b769d4ac-1b9b-4a3d-b399-04abc34aaeb0      Lee Davis   \n",
      "3         4  AliExpress  e849cdda-2ff9-4fac-b531-40b021d504ec      Jing Wang   \n",
      "4         5  AliExpress  d8989ff9-2a7e-406b-8dfd-faf8bd48c884   Kari Eilrich   \n",
      "\n",
      "                                        UserImageURL  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
      "\n",
      "                                          ReviewText  Rating  ThumbsUpCount  \\\n",
      "0  Good prices but awful shipping fees. Difficult...       2             24   \n",
      "1  Easy experience the last few years. Have done ...       5           1444   \n",
      "2  Alright. There's a LOT good deals, save for th...       5            161   \n",
      "3  extremely bad. when its affiliated store cance...       1            131   \n",
      "4  The first order of 3 items for .99Â¢ is real. H...       1            830   \n",
      "\n",
      "  AppVersion          ReviewDate ReplyContent RepliedAt  \\\n",
      "0    8.133.3 2025-07-18 03:22:39         None       NaT   \n",
      "1    8.129.3 2025-05-26 11:23:12         None       NaT   \n",
      "2    8.131.2 2025-07-04 21:14:16         None       NaT   \n",
      "3    8.131.2 2025-06-29 09:30:11         None       NaT   \n",
      "4    8.122.3 2025-03-08 03:32:58         None       NaT   \n",
      "\n",
      "                   ScrapedAt  \n",
      "0 2025-07-25 22:36:06.313333  \n",
      "1 2025-07-25 22:36:06.323333  \n",
      "2 2025-07-25 22:36:06.330000  \n",
      "3 2025-07-25 22:36:06.336666  \n",
      "4 2025-07-25 22:36:06.343333  \n",
      "\n",
      "--- DataFrame Shape ---\n",
      "(1500, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_5128\\103105414.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# --- Database Connection Configuration (Update as needed) ---\n",
    "SERVER = 'localhost' # Replace with your server name/IP\n",
    "DATABASE = 'PlayStoreReviewsDB'\n",
    "CONNECTION_STRING = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;'\n",
    "\n",
    "def load_data_from_db():\n",
    "    try:\n",
    "        conn = pyodbc.connect(CONNECTION_STRING)\n",
    "        print(\"Connected to SQL Server successfully.\")\n",
    "        query = \"SELECT * FROM dbo.AppReviews\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Data loaded into DataFrame successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading  {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- THIS LINE IS CRUCIAL ---\n",
    "df = load_data_from_db() # <-- This assigns the loaded data to the variable 'df'\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- DataFrame Shape ---\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d186c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text cleaning and preprocessing...\n",
      "Text cleaning and preprocessing completed.\n",
      "\n",
      "--- Sample Original vs Cleaned Text ---\n",
      "Original:\n",
      "Good prices but awful shipping fees. Difficult to track shipping progress on orders: no arrival estimations or delivery notifications. Products often come as incorrect or flawed. Floods inboxes with spam. Store page is inconvenient to navigate. Whatever item you're looking for will be in a compilation of things under generic names (such as \"114A\" or \"blue person\").\n",
      "\n",
      "Cleaned:\n",
      "good price awful shipping fee difficult track shipping progress order arrival estimation delivery notification product often come incorrect flawed flood inboxes spam store page inconvenient navigate whatever item looking compilation thing generic name blue person\n",
      "\n",
      "Original Word Count: 57\n",
      "Cleaned Word Count: 35\n",
      "\n",
      "--- Another Sample ---\n",
      "Original:\n",
      "Easy experience the last few years. Have done some shopping for tech parts you wouldn't really find in the US. I went up to buying figurines and have not had an error in my orders, all parts were always included. The deals are what brings me back, some very costly items can be up to half off if you play your cards right, just make use of the games to get coins!\n",
      "\n",
      "Cleaned:\n",
      "easy experience last year done shopping tech part would really find u went buying figurine error order part always included deal brings back costly item half play card right make use game get coin\n",
      "\n",
      "Number of reviews that became empty after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Apply Text Cleaning Function\n",
    "print(\"Starting text cleaning and preprocessing...\")\n",
    "# Apply the function to the 'ReviewText' column\n",
    "# This might take a minute or two depending on your dataset size\n",
    "df['CleanedReviewText'] = df['ReviewText'].apply(clean_and_preprocess_text)\n",
    "print(\"Text cleaning and preprocessing completed.\")\n",
    "\n",
    "# --- Optional: Feature Engineering ---\n",
    "# Calculate review length (number of words in cleaned text)\n",
    "df['ReviewWordCount'] = df['CleanedReviewText'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "# --- Inspect Results ---\n",
    "print(\"\\n--- Sample Original vs Cleaned Text ---\")\n",
    "print(\"Original:\")\n",
    "print(df['ReviewText'].iloc[0])\n",
    "print(\"\\nCleaned:\")\n",
    "print(df['CleanedReviewText'].iloc[0])\n",
    "print(f\"\\nOriginal Word Count: {len(df['ReviewText'].iloc[0].split())}\")\n",
    "print(f\"Cleaned Word Count: {df['ReviewWordCount'].iloc[0]}\")\n",
    "\n",
    "print(\"\\n--- Another Sample ---\")\n",
    "print(\"Original:\")\n",
    "print(df['ReviewText'].iloc[1])\n",
    "print(\"\\nCleaned:\")\n",
    "print(df['CleanedReviewText'].iloc[1])\n",
    "\n",
    "# Check for rows where cleaning resulted in empty strings\n",
    "empty_after_cleaning = df[df['CleanedReviewText'] == '']\n",
    "print(f\"\\nNumber of reviews that became empty after cleaning: {len(empty_after_cleaning)}\")\n",
    "if len(empty_after_cleaning) > 0:\n",
    "    print(\"Dropping these rows...\")\n",
    "    df = df[df['CleanedReviewText'] != ''].reset_index(drop=True)\n",
    "    print(f\"Final DataFrame shape after dropping empty cleaned texts: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff54832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_reviews_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Cleaned Data\n",
    "output_filename = 'cleaned_reviews_data.csv'\n",
    "df.to_csv(output_filename, index=False) # Don't save the DataFrame index\n",
    "print(f\"Cleaned data saved to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bc3bb-0c8c-424d-b2a3-7ee21d417e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
